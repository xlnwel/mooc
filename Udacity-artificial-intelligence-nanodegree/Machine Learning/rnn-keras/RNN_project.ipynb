{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Recurrent Neural Network Projects\n",
    "\n",
    "Welcome to the Recurrent Neural Network Project in the Artificial Intelligence Nanodegree! In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully!\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation TODOs in this notebook\n",
    "\n",
    "This notebook contains two problems, cut into a variety of TODOs.  Make sure to complete each section containing a TODO marker throughout the notebook.  For convenience we provide links to each of these sections below.\n",
    "\n",
    "[TODO #1: Implement a function to window time series](#TODO_1)\n",
    "\n",
    "[TODO #2: Create a simple RNN model using keras to perform regression](#TODO_2)\n",
    "\n",
    "[TODO #3: Finish cleaning a large text corpus](#TODO_3)\n",
    "\n",
    "[TODO #4: Implement a function to window a large text corpus](#TODO_4)\n",
    "\n",
    "[TODO #5: Create a simple RNN model using keras to perform multiclass classification](#TODO_5)\n",
    "\n",
    "[TODO #6: Generate text using a fully trained RNN model and a variety of input sequences](#TODO_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Perform time series prediction \n",
    "\n",
    "In this project you will perform time series prediction using a Recurrent Neural Network regressor.  In particular you will re-create the figure shown in the notes - where the stock price of Apple was forecasted (or predicted) 7 days in advance.  In completing this exercise you will learn how to construct RNNs using Keras, which will also aid in completing the second project in this notebook.\n",
    "\n",
    "The particular network architecture we will employ for our RNN is known as  [Long Term Short Memory (LSTM)](https://en.wikipedia.org/wiki/Long_short-term_memory), which helps significantly avoid technical problems with optimization of RNNs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Getting started\n",
    "\n",
    "First we must load in our time series - a history of around 140 days of Apple's stock price.  Then we need to perform a number of pre-processing steps to prepare it for use with an RNN model.  First off, it is good practice to normalize time series - by normalizing its range.  This helps us avoid serious numerical issues associated how common activation functions (like tanh) transform very large (positive or negative) numbers, as well as helping us to avoid related issues when computing derivatives.\n",
    "\n",
    "Here we normalize the series to lie in the range [0,1] [using this scikit function](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html), but it is also commonplace to normalize by a series standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aptx4869/anaconda3/envs/ai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "### Load in necessary libraries for data input and normalization\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from my_answers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from my_answers import *\n",
    "\n",
    "### load in and normalize the dataset\n",
    "dataset = np.loadtxt('datasets/normalized_apple_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at the (normalized) time series we'll be performing predictions on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'normalized series value')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c5e0240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets take a look at our time series\n",
    "plt.plot(dataset)\n",
    "plt.xlabel('time period')\n",
    "plt.ylabel('normalized series value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Cutting our time series into sequences\n",
    "\n",
    "Remember, our time series is a sequence of numbers that we can represent in general mathematically as \n",
    "\n",
    "$$s_{0},s_{1},s_{2},...,s_{P}$$\n",
    "\n",
    "where $s_{p}$ is the numerical value of the time series at time period $p$ and where $P$ is the total length of the series.  In order to apply our RNN we treat the time series prediction problem as a regression problem, and so need to use a sliding window to construct a set of associated input/output pairs to regress on.  This process is animated in the gif below.\n",
    "\n",
    "<img src=\"images/timeseries_windowing_training.gif\" width=600 height=600/>\n",
    "\n",
    "For example - using a window of size T = 5 (as illustrated in the gif above) we produce a set of input/output pairs like the one shown in the table below\n",
    "\n",
    "$$\\begin{array}{c|c}\n",
    "\\text{Input} & \\text{Output}\\\\\n",
    "\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n",
    "\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n",
    "\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n",
    "\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n",
    "\\end{array}$$\n",
    "\n",
    "Notice here that each input is a sequence (or vector) of length 5 (and in general has length equal to the window size T) while each corresponding output is a scalar value.  Notice also how given a time series of length P and window size T = 5 as shown above, we created P - 5  input/output pairs.  More generally, for a window size T we create P - T such pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time for you to window the input time series as described above!  \n",
    "\n",
    "<a id='TODO_1'></a>\n",
    "\n",
    "**TODO:** Implement the function called **window_transform_series** in my_answers.py so that it runs a sliding window along the input series and creates associated input/output pairs.    Note that this function should input a) the series and b) the window length, and return the input/output subsequences.  Make sure to format returned input/output as generally shown in table above (where window_size = 5), and make sure your returned input is a numpy array.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test your function on the list of odd numbers given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_nums = np.array([1,3,5,7,9,11,13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a hard-coded solution for odd_nums.  You can compare its results with what you get from your **window_transform_series** implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- the input X will look like ----\n",
      "[[ 1  3]\n",
      " [ 3  5]\n",
      " [ 5  7]\n",
      " [ 7  9]\n",
      " [ 9 11]]\n",
      "--- the associated output y will look like ----\n",
      "[[ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]\n",
      " [13]]\n"
     ]
    }
   ],
   "source": [
    "# run a window of size 2 over the odd number sequence and display the results\n",
    "window_size = 2\n",
    "\n",
    "X = []\n",
    "X.append(odd_nums[0:2])\n",
    "X.append(odd_nums[1:3])\n",
    "X.append(odd_nums[2:4])\n",
    "X.append(odd_nums[3:5])\n",
    "X.append(odd_nums[4:6])\n",
    "\n",
    "y = odd_nums[2:]\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "y = np.reshape(y, (len(y),1)) #optional\n",
    "\n",
    "assert(type(X).__name__ == 'ndarray')\n",
    "assert(type(y).__name__ == 'ndarray')\n",
    "assert(X.shape == (5,2))\n",
    "assert(y.shape in [(5,1), (5,)])\n",
    "\n",
    "# print out input/output pairs --> here input = X, corresponding output = y\n",
    "print ('--- the input X will look like ----')\n",
    "print (X)\n",
    "\n",
    "print ('--- the associated output y will look like ----')\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again - you can check that your completed **window_transform_series** function works correctly by trying it on the odd_nums sequence - you should get the above output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3]\n",
      " [ 3  5]\n",
      " [ 5  7]\n",
      " [ 7  9]\n",
      " [ 9 11]]\n",
      "[[ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]\n",
      " [13]]\n"
     ]
    }
   ],
   "source": [
    "### TODO: implement the function window_transform_series in the file my_answers.py\n",
    "from my_answers import window_transform_series\n",
    "X, y = window_transform_series(odd_nums, 2)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function in place apply it to the series in the Python cell below.  We use a window_size = 7 for these experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window the data using your windowing function\n",
    "window_size = 7\n",
    "X,y = window_transform_series(series = dataset,window_size = window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Splitting into training and testing sets\n",
    "\n",
    "In order to perform proper testing on our dataset we will lop off the last 1/3 of it for validation (or testing).  This is that once we train our model we have something to test it on (like any regression problem!).  This splitting into training/testing sets is done in the cell below.\n",
    "\n",
    "Note how here we are **not** splitting the dataset *randomly* as one typically would do when validating a regression model.  This is because our input/output pairs *are related temporally*.   We don't want to validate our model by training on a random subset of the series and then testing on another random subset, as this simulates the scenario that we receive new points *within the timeframe of our training set*.  \n",
    "\n",
    "We want to train on one solid chunk of the series (in our case, the first full 2/3 of it), and validate on a later chunk (the last 1/3) as this simulates how we would predict *future* values of a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our dataset into training / testing sets\n",
    "train_test_split = int(np.ceil(2*len(y)/float(3)))   # set the split point\n",
    "\n",
    "# partition the training set\n",
    "X_train = X[:train_test_split,:]\n",
    "y_train = y[:train_test_split]\n",
    "\n",
    "# keep the last chunk for testing\n",
    "X_test = X[train_test_split:,:]\n",
    "y_test = y[train_test_split:]\n",
    "\n",
    "# NOTE: to use keras's RNN LSTM module our input must be reshaped to [samples, window size, stepsize] \n",
    "X_train = np.asarray(np.reshape(X_train, (X_train.shape[0], window_size, 1)))\n",
    "X_test = np.asarray(np.reshape(X_test, (X_test.shape[0], window_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_2'></a>\n",
    "\n",
    "## 1.4  Build and run an RNN regression model\n",
    "\n",
    "Having created input/output pairs out of our time series and cut this into training/testing sets, we can now begin setting up our RNN.  We use Keras to quickly build a two hidden layer RNN of the following specifications\n",
    "\n",
    "- layer 1 uses an LSTM module with 5 hidden units (note here the input_shape = (window_size,1))\n",
    "- layer 2 uses a fully connected module with one unit\n",
    "- the 'mean_squared_error' loss should be used (remember: we are performing regression here)\n",
    "\n",
    "This can be constructed using just a few lines - see e.g., the [general Keras documentation](https://keras.io/getting-started/sequential-model-guide/) and the [LSTM documentation in particular](https://keras.io/layers/recurrent/) for examples of how to quickly use Keras to build neural network models.  Make sure you are initializing your optimizer given the [keras-recommended approach for RNNs](https://keras.io/optimizers/) \n",
    "\n",
    "(given in the cell below).  (remember to copy your completed function into the script *my_answers.py* function titled *build_part1_RNN* before submitting your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: create required RNN model\n",
    "# import keras network libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import keras\n",
    "\n",
    "# given - fix random seed - so we can all reproduce the same results on our default time series\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# TODO: implement build_part1_RNN in my_answers.py\n",
    "from my_answers import build_part1_RNN\n",
    "model = build_part1_RNN(window_size)\n",
    "\n",
    "# build model using keras documentation recommended optimizer initialization\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your model built you can now fit the model by activating the cell below!  Note: the number of epochs (np_epochs) and batch_size are preset (so we can all produce the same results).  You can choose to toggle the verbose parameter - which gives you regular updates on the progress of the algorithm - on and off by setting it to 1 or 0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181651feb8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run your model!\n",
    "model.fit(X_train, y_train,  \n",
    "          epochs=1000, batch_size=50, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5  Checking model performance\n",
    "\n",
    "With your model fit we can now make predictions on both our training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for training\n",
    "model.load_weights=('best_model.hdf5')\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we compute training and testing errors using our trained model - you should be able to achieve at least\n",
    "\n",
    "*training_error* < 0.02\n",
    "\n",
    "and \n",
    "\n",
    "*testing_error* < 0.02\n",
    "\n",
    "with your fully trained model.  \n",
    "\n",
    "If either or both of your accuracies are larger than 0.02 re-train your model - increasing the number of epochs you take (a maximum of around 1,000 should do the job) and/or adjusting your batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = [0.016003980724648995, 0.022727272727272728]\n",
      "testing error = [0.013984095716719018, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# print out training and testing errors\n",
    "training_error = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('training error = ' + str(training_error))\n",
    "\n",
    "testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('testing error = ' + str(testing_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activating the next cell plots the original data, as well as both predictions on the training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAEKCAYAAABkC+0BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd4lFXawOHfSe8F0kiA9ASS0GOQIiBYQAUUFBELNsBe1l37ByzWVddeFgt2V5RFV4q40hUwkFDSQwqhJYQUSC8kc74/3pkYQsoAM5mQnPu6xmTe+gQw87ynPUJKiaIoiqIoPYuVpQNQFEVRFKXzqQRAURRFUXoglQAoiqIoSg+kEgBFURRF6YFUAqAoiqIoPZBKABRFURSlB1IJgKIoiqL0QCoBUBRFUZQeSCUAiqIoitID2Vg6gM7k5eUlg4KCLB2GoijKBSUxMbFYSult6TgU0+pRCUBQUBAJCQmWDkNRFOWCIoQ4aOkYFNNTXQCKoiiK0gOpBEBRFEVReiCVACiKoihKD6QSAEVRFEXpgVQCoCiKoig9kEUTACHEMiHEcSFEShv7hRDibSFEthAiSQgxvNm+uUKILP1rbudFrSiKoigXPku3AHwGTG5n/xQgXP+aD3wAIIToBSwCRgJxwCIhhKdZI1UURVGUbsSiCYCUcitQ2s4h04EvpOYPwEMI0Qe4EvhVSlkqpTwB/Er7iYSiAKDT6fj444+prq62dCiKoigWZekWgI4EAIebvT+i39bW9jMIIeYLIRKEEAlFRUVmC1S5MPz222/MmzePjz/+2NKhKIqiWFRXTwBEK9tkO9vP3Cjlh1LKWCllrLe3Wsmyp0tMTARgzZo1Fo5EURTFsrp6AnAE6NfsfV8gv53titKu3bt3A7B582YqKystHI2iKIrldPUE4CfgNv1sgIuBMillAfALcIUQwlM/+O8K/TZFadfu3bvx8fGhvr6e9evXWzocRVEUi7H0NMB/AzuASCHEESHEXUKIe4QQ9+gPWQvkAtnAR8B9AFLKUuA5YJf+tUS/TVHaVFVVRUZGBnfffTfu7u6sXr3a0iEpiqJYjEWrAUopb+pgvwTub2PfMmCZOeJSuqd9+/YhpWTkyJFkZWXz1VczmThRx5w5Xb0hTFEUxfTUbz6lxzD0/w8fPpzY2Juoq5vCiy+q6YCKovRMKgFQegxD/39AQADW1pcBkJrqwqFDFg5MURTFAlQCoPQYu3fvZvjw4Qgh2LXLBSurKgBWrrRwYIqiKBagEgClR6itrSU1NZXhw4cjJWzeDOHhaQiRwooVOkuHpyiK0ulUAqD0CMnJyTQ0NDB8+HAyMqCwEMaPBym/Z/t2wbFjlo5QURSlc6kEQOmWHn30Ud57772m9wkJCYA2AHDTJm3b3Ln9gf8gpeCHHywQpKIoigWpBEDplj7//HPefffdpvdbtmwhICCAoKAgNm2Cfv1g1ChfgoNrcHE5yo8/WjBYRVEUC1AJgNLtlJeXc+LECTIyMvj990I2bZJs3ryZCRMmIKVg82a49FIQAi65ZCwNDeuJj5fo1FAARVF6EJUAKN3OwYMHm77/299quOoqSWFhNRMmTGD3bigu1hIAgLFjx1Jbu5WyMkFOjoUCVhRFsQCVACjdTl5eXtP3OTmN1NZaATdy6aWX8tFH4OgI116r7R87diygjQ/YtavTQ1UURbEYlQAo3Y4hARg7diylpS4A2NktwMsrhK+/hptuAg8P7dgBAwbQq9cxrK3rVAKgKEqPohIApds5ePAgDg4OzJw5h8ZGX6CQ+vpYnn1WUFUF99zz57FCCC6+OBZ7+zT0EwUURVF6hA4TACHEkhbvrYUQX5svJEU5P3l5eQQGBhIdfaV+y+tYW+t4910YPhxiY08/fsCAAdTVbWf3bklDQ6eHqyiKYhHGtAD0F0I8BSCEsAd+ALLMGpWinIeDBw8SFBSElVWwfssuJk2qAbSnfyFOPz4yMpLGxh1UVwvS0zs3VkVRFEsxJgG4AxikTwJWAZuklIvNGpWinAdDC8Dhw9onfUiILYsXOzF5stb/31JkZCSGgYCqG0BRlJ6izQRACDFcCDEcGAa8BdyI9uS/Rb/9vAkhJgshMoUQ2UKIJ1vZ/4YQYq/+tV8IcbLZvsZm+34yRTzKha+qqori4mKCgoKaqvz98cf3jBol+PlncHE58xwtAdiPg4MaCKgoSs9h086+f7Z4fwKI0m+XwMTzubEQwhp4D7gcOALsEkL8JKVMMxwjpXy02fEPoiUjBjVSyqHnE4PS/RjWAAgKCmL9evDzA29vt3bP8fX1xc3NFVfXPHbtiuyMMBVFUSyuzQRASnmpme8dB2RLKXMBhBDfAtOBtDaOvwlYZOaYlAucYQpgYGAghw5BYGDH5wghiIyMpLBwH0lJkTQ0gE17qbGiKEo3YMwsgBeFEB7N3nsKIZ43wb0DgMPN3h/Rb2sthkAgGNjYbLODECJBCPGHEOJaE8SjdAPNWwAOHoT+/Y07LzIykoqKndTXQ7OFBBVFUbotYwYBTpFSNvW9SylPAFeZ4N6ilW2yjWNnAyuklI3NtvWXUsYCc4A3hRChrd5EiPn6RCGhqKjo/CJWury8vDzs7Ozw9fUzugUAtATgxIl4ALLUHBdFUXoAYxIAa/30PwCEEI6AfTvHG+sI0K/Z+75AfhvHzgb+3XyDlDJf/zUX2Mzp4wOaH/ehlDJWShnr7e19vjErXVxeXh79+/enuNiKurqzawGA/QDs32+++BRFUboKYxKAr4ANQoi7hBB3Ar8Cn5vg3ruAcCFEsBDCDu1D/ozR/EKISMAT2NFsm6chKRFCeAFjaHvsgNKDGNYAMMwAOJsWADiOo+Mp1QKgKEqP0OFQJynlK0KIJOAy/abnpJS/nO+NpZQNQogHgF8Aa2CZlDJVv/JggpTSkAzcBHwrpWzePTAQWCqE0KElMS83nz2g9Fx5eXlcc801Tf34xrYAhIeHI4TA07OI/fv9zRegoihKF2HsWOc9gC1aH/0eU91cSrkWWNti28IW7xe3ct52YJCp4lC6h5qaGgoLC5tmAIDxCYCjoyP9+/cH8sjKUgmAoijdnzGzAGYBO4HrgVlAvBDienMHpihn68CBAwCEhIRw8KC26I+np/HnR0ZGUl+fwsGDUFdnpiAVRVG6CGPGADwDXCSlnCulvA1t/v7/mTcsRTl7OTk5AISFhXHokPb033Ld//ZERkZSWroTnQ5yc80UpKIoShdhTAJgJaU83ux9iZHnKUqnys7OBiA0NJSDB40fAGgQFxdHXV0SoKYCKorS/RnzQb5OCPGLEOJ2IcTtwBrgZ/OGpShnLycnB3d3d3r16k1ODgQHd3xOc5deeimGQpdqKqCiKN2dMbMA/iaEmAGMRVu850Mp5Q9mj0xRzlJ2djZhYWEUFwvKyyEi4uzODwgIICLCh7y8MrKy3M0TpKIoShdhzCDAf0gpV0op/yKlfFRK+YMQ4h+dEZyinI2cnBxCQ0Obnt7PNgEArRWgsTGD/ft1pg1OURSlizGmC+DyVrZNMXUginI+Tp06RV5eHmFhYU399+eeAKSTmtpg2gAVRVG6mDYTACHEvUKIZCBSCJHU7HUASOq8EBWlY4cOHaKhoaGpBcDG5uwHAQJMmDAByKKoyI6qKlNHqSiK0nW01wLwDTAVbXneqc1eI6SUt3RCbIpitOZTAPfvh9DQcyvp6+vrS9++1YAaCKgoSvfWZgIgpSyTUuYBzwLHpJQH0Ury3tK8PLCidAXNpwBmZZ1b87/BhAluAGzf3tjBkYqiKBcuY8YA/AdoFEKEAZ+gJQHfmDUqpUuqrtY+WH/80dKRnCknJwdHR0d8ffuQlQXh4ed+rWnTBgEFrF59wmTxKYqidDXGJAA6KWUDMAN4U0r5KNDHvGEpXdGePdoCOT90wUmg2dnZhIaGUlBgRW3t+bUAXHRRLLCNhAQ7k8WnKIrS1RiTAJwSQtwE3Aas1m+zNV9ISleVkKB9/eMPy8bRmpZTAM+nBSAwMBAHh90UF7tRUGCa+BRFUboaYxKAO4BRwAtSygNCiGDgK/OGpXQl9fX1fPzxx8THa3Pj9++HkhILB9WMTqcjJyenaQAgnF8LgBCCAQO0H3DbNhMEqCiK0gV1mABIKdOklA9JKf+tf39ASvmy+UNTuopVq1Yxb948tm6txttb2xYfb9mYmisoKKC2trZpAKCTE/ifZ0Xf0aOdgBp+/12aJEZFUZSuRhX1UTqUkZEBuHL0qAt33glWVl2rGyAlJQWgqQsgLEyL8XyMGDEI2MmmTaousKIo3ZNFEwAhxGQhRKYQIlsI8WQr+28XQhQJIfbqX3c32zdXCJGlf83t3Mh7lszMTGA4ABMmwODBsGOHRUNqotPpWLRoEb6+vowaNeq8pwAaDBkyBNhGaqod1dXnfz1FUZSuxugEQAjhbMobCyGsgffQlhWOAm4SQkS1cuhyKeVQ/etj/bm9gEXASCAOWCSE8DRlfMqftATgIgAGD67n4ou1LoDGLjBN/pNPPiE+Pp7XXnsNe3tXcnNNkwBER0djZfUHjY1W7Nx5/tdTFEXpaowpBjRaCJEGpOvfDxFCvG+Ce8cB2VLKXCllPfAtMN3Ic68EfpVSlkopTwC/ApNNEJPSgpSSzMxMHB0vAQ5w6NBuRo2CigpIT7dsbMXFxTz55JOMHz+em2++mS++gIYGGDv2/K/t4OBAeHgx0LW6OxRFUUzFmBaAN9A+cEsApJT7gHEmuHcAcLjZ+yP6bS3N1NcgWCGE6HeW5yrn6fjx45SVlWFvPwZIYNu2bYwape2z9AfjBx98wIkTJ3jvvfeorxcsWQJxcTDZRKlgbGwI1taH2L3bNNdTFEXpSozqApBSHm6xyRSNv6K1W7V4vwoIklIOBtYDn5/FudqBQswXQiQIIRKKiorOOdieateuHGAAJ0/2plevXLZt20ZYGPTubfkEIC0tjeDgYKKjo1m6FA4fhhdeANHav45zMGTIEBobd5KY2AX6OhRFUUzMmATgsBBiNCCFEHZCiL+i7w44T0eAfs3e9wXymx8gpSyRUhqGYX8EjDD23GbX+FBKGSuljPU2zGFTjLJ4MUydOhrDX/eIETq2bdsGSMLD4eBBS0anrf4XFhZGVZX2wT9hAkyaZLrrDx06FNhDbq41ZWWmu66iKEpXYEwCcA9wP1oT+xFgqP79+doFhAshgoUQdsBstMqDTYQQzZccnsaficcvwBVCCE/94L8r9NsUE9m1C557DkJDU7CxuY/ly3Vcd10vjh8/Tk5ODn5+cOyY5eKTUpKVlUVYWBg//wzHj8PChaZ7+gdDAqC1/+/da7rrKoqidAUdFkyVUhYDN5v6xlLKBiHEA2gf3NbAMillqhBiCZAgpfwJeEgIMQ1oAEqB2/XnlgohnkNLIgCWSClLTR1jT1VfD3feCX36QFjYczg5pTNrlhUpKWMA2L59O336hPH775aLsbS0lLKyMsLCwkhK0ub9G8YmmIq3tzcBAcc5elSrgzB+vGmvryiKYkltJgBCiHdoo18dQEr50PneXEq5FljbYtvCZt8/BTzVxrnLgGXnG4NypldfhZQUWLUK/vKXPfo58TBgwACEEOTm5uLnB8XFWrJgZ4GaOYbyv2FhYXzyiTb1z8HB9PcZNSqEH34oZPduX9NfXFEUxYLa6wJIABLbeSnd1Lp12tP0FVfUk5ubS2RkJAA2NjZ4eXlx7Ngx/Py0Y48f75yYkpNh5kz4Sd9J1DwBSE7WFicyh7i4OBobd7FrV4N5bqAoimIhbbYASCk/b/5eCOGmbZYVZo9KsajiYhg0CHJzc2lsbCSi2co6fn5+pyUAx45B376mj+GXX35hxowZ2NjYIsQ/qKycT2OjIC8Ppk3Tqv8JIfDyCiY3F+64w/QxgJYAwBb277+a6mqtzoCiKEp3YMxCQLFCiGQgCUgRQuwTQozo6DzlwlVUBN7ehhUAaWoBgD8TgD764ZnmGgj466+/0tjYyOWX/52ysgWEhu5k0SLYvVvrnsjOzqZfv37k5Gjt/uZqARgxYgRC7EOnEyQnm+ceiqIolmDMLIBlwH1SyiApZSDaDIBPzRuWYimNjVBaCvb2FXz88cdA6wlA8xYAc0hKSiImJoaLL34YgJKS25k/vwEbG/jyyz+nACYlaccPGmSeOFxcXAgP1xq91IJAiqJ0J8YkABVSyt8Mb6SUvwOqG6Cb2rUrGynhvfcW88svv7Bo0SI8PDya9hsSAG9vbXxoQYF54khKSmLw4MHs3Am+vlWUlGSQkrKRKVPgq68gKyu3qf/f1RUCA80TB8CYMf0QopSEBFUaWFGU7sOYBGCnEGKpEGKCEGK8vg7AZiHEcCHEcHMHqHSeG264gVGjpgIwYkR/0tPTWbx48WnH+Pn5UVdXR21tGb16QWbmSTZv3mzSOAoLCyksLGTw4MHEx8Mllzjg5ubGt99+y223QX4+FBcPamoBiIk5//K/7Rk5Mg4p/2Dr1lPmu4miKEonM+bX5lAgAq363mJgIDAa+CfwmtkiUzqVTqdj5cqVjB17HQBLljxMaGjoGcf56dv+Dd0AW7bsZ/bs2SaNJVnf2d63byyHDsHo0dZcd911rFy5kssvr8PVtQFYQGioeWcAGGgDAX8jO9uO4mLz3ktRFKWzdJgASCkvbec1sTOCVMyvrKwMnU5HWJi2mk5bqyY3TwD69IETJ+wpLCykvr7eZLEk6Tv2a2u1jv24OJg9ezZlZWVs3LiWK67IBK5n8+ZRnDhhvv5/g5iYGOzstJrA27aZ916KoiidxZhZAL2FEG8LIXYLIRKFEG8JIXp3RnBK5ykpKdF/56X916v141q2ANTUuDW9N5WkpCT69OlDRoY71tYwbBhMmjSJfv36cc8992Bj8xKwiXfe0WIxdwuAra0tY8bYIUQdW7d2PA7gwQcf5OGHHzZvUIqiKOfJmC6Ab4EiYCZwvf775eYMSul8xfq27cbGXoBxCYCHRy06nQ8Aq1dXMHQoVFaefyzNBwAOGqTNvbe1teXXX3/Fzs6O5cu/xsfn4aapiDEx53/Pjlx//VSk3Mmvv9a0e5yUkuXLl7N9+3bzB6UoRpBSDV5VWmdMAtBLSvmclPKA/vU84NHhWcoFxdACcOqUG66uYG/f+nGenp7Y2tpy7NgxrK2LAGfAlVWrHNi3D/RLB5yzhoYGUlNTGTRoCLt2wciRf+6LjIzk999/Jzw8nNjYfvz8M7z9Nnh6nt89jXHdddcBv5Oaak9VVdvHHTx4kKKiIsrLy80flKIYYd26dQQGBpKammrpUJQuxpgEYJMQYrYQwkr/mgWsMXdgSucyJAA1Nc5tPv0DCCGapgLqdEf1W/1ISnIHIC+v43s1NDTw3//+t9Unk/3791NfX4+PzxhOntT6/5sLDAwkKSmJFStWMGQIPPigET+cCfTp04eoqBJ0Omvi49s+btcurT5VeXk5n38Oo0d3TnyK0pb4+HgOHz5M//79LR2K0sUYkwAsAL4B6oB6tC6BvwghKoQQ6jGnmzAkABUVjm0OADQwJADV1bkACDGQ/Hyt68CYBGDNmjVce+21rF+/gSVLQL+sP/DnAMATJ7TFJlsmAAAODg44Ojp2fCMTu+WWEEDHjz+WtHlM8wRg9WrYsQNq2u81UBSz2rlzJ9HR0bi6ulo6FKWLMWYWgKuU0kpKaSultNF/76p/uXVGkIr5lZSUYGVlRVmZTbstAPBnAnDyZAYAjo5zMPxTMiYBMCwxvGZNGosWwd///ue+ffv2YW3tzUcf+TN6NERHn8MPYyY333wNsI+1a9teB2vnTm22QHV1NUlJWgvHiROdEZ2inElKyc6dO/VTWRXldGe1fIoQIlQI8YwQIsVcASmWUVJSQq9evSgqEkYnAIWF+wCoq5uMEI2EhsKBAx3fy1DJb9s2beDhf/4DZWVQX1/PN998g7f3R5w4IfjgAxDivH4sk+rfvz9+fqnk5ga0WgWxsbGRxMRE7OzsAIemlo3S0k4NU1Ga5ObmUlJSwsjmg2kURc+YaYB9hBCPCiF2AqloFQRvMntkSqcqKSnBy8uL4uK21wAw8PPzo6ioiAMHdmNl1UBjozv29unExBjXAmBIAFJTtRK7NTWwfDl89tlnHDrkR2HhNB56yPzT+87FFVccRkpbPvvszPELmZmZVFZWMmrUKCAKnU7LXlQCoFhKvH7AimoBUFrTZgIghJgnhNgIbAF6A3cDBVLKv0spTVIXTQgxWQiRKYTIFkI82cr+vwgh0oQQSUKIDUKIwGb7GoUQe/Wvn0wRT09WXFyMh4c/1dVtTwE08PPzQ6fTkZ9/BBcXbUi8lL8TFKQlAB3NOsrOzsbBwYGamr64uzcSHQ3Llul47rkPsbP7AX9/aLECcZcxfLgT8Dsffth4xs9paP6fNGkS8OfqRCoBUCxl586dODo6EtMZc2WVC057LQDvAdbAHCnls1LKJMBkE0qFENb6e0wBooCbhBBRLQ7bA8RKKQcDK4BXmu2rkVIO1b+mmSqunqqkpAQXlyDAuBYAAy8vbX38urr1BATUU1UFJW2PkaOmpobDhw8zffp0IBIvrxLuvBPi4604cuQrhPDhxx8Fbl10dElwcDDwETk5Nmzdevq+Xbt24erqSmxsLM0TADUGQLGU+Ph4RowYgY2NjaVDUbqg9hIAf7QR/6/rn9KfA2xNeO84IFtKmSulNMwumN78ACnlJilltf7tH0BfE95faaakpARHx36AcS0ABn36GP4JbcPVVXvUba8b4IB+kMA111yDEAOwts5hxoxq4BQQznffWRMbe24/Q2cICgoCvsfJqZ6PPjp9386dO4mNjdVXTxxMQIDWOqJaABRLqK+vZ8+ePar/X2lTmwmAlLJYSvmBlHIcMAkoA44LIdKFEC+a4N4BwOFm74/ot7XlLuDnZu8dhBAJQog/hBDXtnWSEGK+/riEoqKi84u4GyspKcHOTvvjP5sE4OKL7YiMLAOO4eCg1QZuLwEw9P/37TsAKQMoL0/g889fBR5k8eIMpk3rQqP+WhEYGAjUMGRICitWQIV+QoBOpyM5OZnhw4fj5uYGDCIsrAhra5UAdHtSwv79lo7iDElJSdTV1akEQGmTUe1CUsojaJX/XhNCRAKmKP/W2m/6VrsYhBC3ALHA+Gab+0sp84UQIcBGIUSylDLnjAtK+SHwIUBsbKxaE7MV1dXV1NbWYm3tC3TcBeDrqx3n7OzMq686M3duKoMHg5R5wDCjEgAhIgAoLPyNl19exaxZ01i0qAvN+WuDu7s7np6euLvHU1c3nLQ0bbXC4uJi6urqCAwM5NQpD8APX994evUKUglAd/fllzB3LsTHt75whYUYxqSYawBgYmKij42NzcdADGc5o0zpFDogpaGh4e4RI0a0Mm/JyASgOSllJvD3Dg/s2BGgX7P3fYH8lgcJIS4DngHGSynrmsWRr/+aK4TYDAwDzkgAlI4ZFgESQvvk76gFwNnZGVdXV4KCghBCEBDgD0BZ2UE8PM5sAcjPz0en09G3b1+ysrLo1asXBQVaJ7+U6QghePXVV036M5lTcHAw1dUJAE0JwNGj2qqIAQEBHDqkrYrYq9cRevUaqRKA7u6zz7Svn3zSpRKA1NRUPDw86O/goJWxHDZMK6xhIjY2Nh/7+fkN9Pb2PmFlZaUerroYnU4nioqKoo4dO/Yx0Oo4OUtmbbuAcCFEsBDCDq1V4bTR/EKIYcBSYJqU8niz7Z5CCHv9917AGCCt0yLvZgwJQGOjJ9bW4GFEpYegoCAGDhwIaPUB7O3tyc/Pb5oJ0Ny8efO47LLLkFKSnZ1NWFgYmZkghMTJqYBnn332glqmNCgoiOPH47G31xIAOD0ByM7Wfsm6uBygVy/VBdCtHT0KmzeDoyN8+y1UV3d4SmcpKirC19cXsXEjjB0LBw+a+hYx3t7e5erDv2uysrKS3t7eZWgtNK0f09YOIcQY/dc2ysKcHyllA/AA8AuQDnwnpUwVQiwRQhiylVcBF+D7FtP9BgIJQoh9wCbgZSmlSgDOkaESYF2dO717g5URaeF//vMf3nzzTUCrD+Dv799mApCbm0tmZiZbt25tSgD274f+/QX5+Tk89dRTpv2BzCwoKIiDB3OJjJSkp2vbmicAqalWQBFSHlMJQDeWnJzMrr/8RRsD8PbbUF4OP/xg6bCaFBcX4+XlBYaxTx317Z09K/Xh37Xp/37a/I3e3q/6t/Vfd5g0omaklGullBFSylAp5Qv6bQullD/pv79MSunbcrqflHK7lHKQlHKI/usn5oqxJzC2EFBz4eHh9DHU4wX8/f05evQoQUHaaoDN58jn52s9O++99x6HDh1qagGIjNT61EVXWu7PCEFBQdTU1BASUndaC4AQAl9fX9LSwM4uk/LycpUAdEcPPAA338yLTz+NzXffUTd0KNx5JwQHw7Jllo6uSVMCcPy4ltX36mXpkCxm/PjxYcXFxdbtHfPII4/4//jjj+dUMGH16tWul156adi5Rde2G2+8MTAxMdHB1Nc1aG8MwCkhxKdAgBDi7ZY7pZQPmSsopXMZEoDKSodzfkjw9/dn3759XHut1gpqWFGwsrKS8vJynJyc+P57GyAJB4ccMjPhjjtM9zN0Jm0tAPD2LiYvry/V1VoC4Ovri62tLTk54OiYT3l5OX5+KgHoVrKy4L33AFgiBOHAhsBAJllZwe23w6JFWhNYUJAFg9QUFxdrAwCPH9f+ZzSmaa+b0el0SCnZsmVLdkfHvvnmm2eMQbOkhoYGli9fbvJ+m+ba+xdxDVrzfC2Q2MpL6SYMCcDJk7ZGtwC0ZOgC8PXV+kBzchoBKCjQpgbee++9wEQgmuefv4rKSoiION/ILSNI/8vd2fkgUkJmppYABAQEUFGhtbi6uBRSXl6Op6fWMnzqlGVjVkzknXfA1pb0J57AV0oagJdy9GOPb71V+7pqlcXCM5BSnt4FYPrm/y5h8eLFvuHh4dHh4eHRS5Ys8QHIzMy0CwkJib7lllv6R0dHR+Xk5NgFBAQMKigosAH429/+1ic4ODh69OjR4VOnTg1euHChL8DMmTODPv30U0+AgICAQY8++qh/VFTUwIiIiKg9e/YazUSDAAAgAElEQVQ4AGzatMlp2LBhAwYOHBg1bNiwAfv27Wu3izwhIcFh0KBBAwcMGBAVERERlZycbA/w/vvv9zJsnzNnTmBDg7YsupOT07BHHnnEf/DgwQM2bNjgEhcXF7l161YngJUrV7oNHTp0QFRU1MApU6aElJWVWQHcd999AaGhodERERFR8+fPP6u1cjpaB+BbtAF4n7d8nc1NlK6tpKQEV9deFBZ2XAioLf7+/lRWVnLLLSMAHdddV8NHH8GhQ1oCMGXKFFxdhwCZ+PpqTf6RkaaJv7NpawGAENoAgLQ0rZsjICAAw2eBp2dpUxcAwMmTlohUMaWU7duRn34KN97IZ1IyysaG5XPnsiElhYyMDO2p38sL9u2zdKhUVFRw6tSpP7sAfHwsHZLJ/fbbb07ffPNN78TExPSEhIT0L774wnvbtm2OAHl5eQ533HFHSXp6elpERES94ZytW7c6rVq1yjM5OTltzZo1OUlJSc5tXd/Ly6shLS0t/c477yx6+eWXfQGGDBlSu3Pnzoz09PS0RYsWHX388cfb/cB95513vO+7777CjIyMtKSkpPTg4OD63bt3O6xYsaJXQkJCRkZGRpqVlZX817/+1RugpqbGKiYmpiYpKSnjyiuvrDRcp6CgwObFF1/ss3Xr1v1paWnpw4cPr37uued8CwsLrdeuXeuZlZWVun///rQXX3yx4Gz+DI2ZBlgihPgBbaS9BH4HHtavDaB0AyUlJVhb/x8nTsBVV53bNa644grWrl3LRRddxGuvTcXa+mPmz3fh+uu1KXH+/v44OgbSu/duduyIYOVKmDjRhD9EJ3J1daV3795UVOzB2hrS07UWgLFjxzYlAF5eZZSWVjQlAKWl3fYhrNtraGjgmWeeoeaVV7SBUQ89xM933YXvJZcw8aWXsPryS/7973/z97//HYYM6RIJgGFgb1MCYOblNe+8885+KSkppptjCMTExFQvW7bscFv7N2/e7HLVVVeddHNz0wFcffXVJzZt2uR6ww03nOzTp0/9pEmTqlo7Z8qUKSddXFwkIC+//PI2U/M5c+acAIiLi6v+6aefPAFKS0utb7zxxuC8vDwHIYQ8depUuwOYRo0aVfXaa6/1OXLkiN3s2bNPDBo0qG7dunWuKSkpTkOGDBkIUFtba+Xj49MAYG1tze23337G4uGbN292zsnJcYiLixsAcOrUKTFixIjKXr16Ndrb2+tmz54dePXVV5fdeOONZe3F05IxnUKfok3P80dbqW+VfpvSTeTkeFBW9gA33wzTzrGqwtChQ9m8eTOvvvoqPj4JTJ68kEGDICVFG1Pj5eVPcbETt946Fl9fwb33gnW7Q3K6tuDgYA4fziE8HJKTGyktLdVPAdT2+/lVndYCoOoBXJjq6+uZPHkyr7zyCo/Z27Md+CAhgeTkZKZMmUKfPn249NJL+eabb5BSaglASgrom3QtxdCt1527AGQ7VcecnJx0Z3tOSw4ODhLAxsZGNjQ0CIAnnngiYPz48RVZWVmpq1atyq6vr2/3M/See+4p/e9//5vt6OiomzJlSsRPP/3kKqUUN9xwQ0lGRkZaRkZGWl5eXsrrr7+eD2BnZ6drrW6DlJKxY8eWG87JyclJ/e677w7a2tqyd+/e9JkzZ5788ccfPSZMmBBu9A+IcS0APlLK5h/4nwkhHjmbmyhdV3097N37CHZ2J3nnnXNs/28hJCSEvLwDREXBzz+74+TkxMmTbuh0EBJikltYXFBQEMnJyURHw9692niHgIAAtm/XWoG9vOxOSwDUQMAL07Zt29iwYQNvL1lC4MKFrPDz42/33w9o3VoAs2fPZt68eaSmphIzZAjU1mqDBfXrZFiCoQXA280NysrM3gXQ3pO6uUycOLHyzjvvDHruueeOSSlZu3at52effZbb3jkTJkyovPfeewOrq6sLTp06JdavX+9x2223Gb1GfHl5uXXfvn3rAZYuXdrhL8y0tDS7gQMH1kVHRx/Pzc2137t3r+PVV19dPmPGjLCnn366MCAgoKGwsNC6rKzMunlXRStxVz322GP9U1JS7GNiYuoqKiqsDhw4YBsYGHiqsrLS6sYbbyybMGFCZURExKC2rtEaY1oAioQQtwghrPWvW4B26r0pF5LERKipCWX48OV4eprmmiEhIeTm5jJgAJSXe+LnF8yBA0K/zzT3sDRtLYCDDBwoOXjQFrBtGgMQGqp1E2iDALUnDpUAXJgMU1ivGTIEgKn6D/+AgACio7Wlq0ePHg3Anj17YPBg7UQLdwMYEgAfwxTbbjgGYOzYsdVz5swpGT58+MARI0YMvPXWW4vGjBlT094548ePr548eXJZVFRU9FVXXRU6ePDgKnd390Zj7/nEE08cW7x4cd/hw4cPaGzs+LQvv/yyV0RERPSAAQOisrKyHBYsWFAyYsSI2mefffbopEmTIiIiIqImTpwYcfjw4XYL7fn7+zcsXbo0b/bs2SERERFRI0aMGJCcnOxw8uRJ68mTJ4dHREREXXLJJZHPP//8WSVixrQA3Am8C7yBNgZgu36b0g0YapiEhZnuEyokJITly5cTEdEIWOPhEUdurmGfyW5jUaGhodTW1uLlVURjow8Q3pQAjBkDbm5uNDQ04ORUCziqBOACZUgAfOu1h7OISZN4w9UVDw+PpvUrIiIisLe3Z+/evdw6axbY2GgJwGxTlEw5N01jAAxN3t2wCwBg8eLFhYsXLy5svi0yMrI+Kysrtfm2o0ePJhu+X7Ro0bHXX389v6KiwmrUqFGRjz/+eCHAf/7zn7zWjh83blz1zp07MwEuu+yyqry8vBTDvrfeeisf4Jprrqm45pprKlrG99JLLx176aWXjrXcPm/evBPz5s07o2Owurp6T/P3hvsCTJs2rWLatGnpLc9JTk4+Y5uxOkwApJSHaGMdYeXCl5GhAxoJDjbdYjzBwcE0Njbi4VEA9MXBYQi5uWBnB/7+JruNRY0bNw6AEye2AtcDsXh7B3D4sNYCoFUEBGvrClQCcOHKz8/H2dkZJ32fOv368fCoUacdY2NjQ0xMDPv27QN7e63pvwu0AFhbW+NiWJq4G7YAnKtbbrklMCsry7Gurk7Mnj27ZOzYsV1n/eZO1vNWhlBOk5paD+Ti42Oi9n+0FgAAKfcDOnS6AeTmaguldZe1SAYOHKhf9nc5Li4nsbaeQWmpNs4hLOzPBKCqqhwPD9UFcKEqKCjA398fjhzR/vE2K4Xd3NChQ9m3b9+fAwFbJAA7duzg5ptvprGuDr74wuwLQxjWABCGZYBVAtBk1apVBzIyMtIOHDiQ2trTeU/STX4dK+cqMbES2H/asr7ny5AApKUlAgeorQ0kN7f7NP+DVv/gyiuvZMOG9fj47ECnu5zUVK0VpXkLgGExIJUAXJjy8/O1/zcOH9aar1oZoQ0wZMgQiouLtYWvhgyB/HxtOUy9hQsX8s0331Dx/vta6eD//c+scXdCHQClG1AJQA/2+utvkp/vTHBwA1dffbXJrhsQEICtrS2///47kE5pqW+3SwBAW/vg5MmTFBR8gJROLF2qbTcMAgRUPYALXFMLwOHD0K9fm8cN0Q8S3Lt3r5YAACQlAZCVlcX69esBsDOUDs7/c9XZ3NxcDh827SD60+oA2NqCu7tJr690Dx0mAEIIXyHEJ0KIn/Xvo4QQd5k/NMWc1q1bx2OPvQ448te/TsXe3nRFH62trQkMDGTbtm1ABkeOeFBWpnUBdCeXXXYZQghqan7G1raK//0PnJ3B1/fPFoCKigqVAFygpJTk5+f/mQD0bXvRN0MCsG/fvjNmAizVZ4aDACd9UsCxP1ue58yZw113mfZX6mktAD4+cIEV3FI6hzEtAJ+h1QQwDN/aD6h1AC5wv//+O1ZW2jzlqChjJoOcnZCQEP1iJOnodN1rCqBB7969iY2NBRoID9cG64aEaL9rm3cBqATgwlReXk51dTV9/Py0MQDttAC4u7sTFBSkJQC+vtCnD+zYQW1tLZ9++ikDBw5kAdBoa6tlifoaGVJK0tPTtfP+9z94/PGzC1Kn01oaWixwc1oLgGr+V9pgTALgJaX8DtABSCkbAKPnTSpdU2ZmJr17a6OZzVGUJ6Tp0z692TbT38fSrrzySgBGjtSe6EJDte0qAbjwGQpZBbm5QU1NuwkAaK0Ae/fu1d5MmwZr1vDDV19RWlrKwsce4xYge9gwrWaAvgWgtFSrGXH8+HHqPvwQXn0VCgvbvMdpMjJg3Dity+H775s263Q6SkpKunUdAIDi4mLrl19++ZyyG3OXB25p2bJlniEhIdEjR46M2Lp1q9Ptt9/eD7Qywr/++mub9QjMzZgEoEoI0RttDQCEEBcDZ7XecFuEEJOFEJlCiGwhxJOt7LcXQizX748XQgQ12/eUfnumEOJKU8TTk2RkZODsPBxnZ+1hxdQMCYCr6599nd2tCwDgKn3xhClTrHB2Bv3aMGckACdOaA9ryoXDsAZAoGHqSjtdAKDNBMjKyqK6uhpuvBGqq9n/5puEhYUxs7YWd2BHTIw2k0CfAOQYikcAp1L008t//73d+0gpKfjsM3SDB2uVqPz8tCqFemVlZTQ2Np7eBdANlZSUWH/yySet/nANHSzFvGXLlmwvL692H2TffPPN/GuvvfaMuf3n4tNPP/V66623DsXHx+8fN25c9WeffXYYYOPGja6//fabiynucS6MSQD+glYLIFQIsQ34AnjwfG8shLAG3gOmAFHATUKIqBaH3QWckFKGoS1E9A/9uVHAbCAamAy8r7+eYoTGxkaysrKACCIizNM9GKz/tO/b1wkfH215XP1nYrcyatQodu3axcyZV7B3LzypT2MdHBywtrZuSgB0Oq0ssHLhMCQAfQwrvhnRAqDT6UhJSYFx42j09iYmNZVbZ83C9h//INHKir0uLm0mAHYH9aXf20kAPv30U/z8/Mi64w4OnjpF/oYN8Ne/aufoxxecUQiom3YBPPbYY30PHz5sP2DAgKgFCxb0Xb16tevIkSMjpk6dGhwZGRkNcNlll4VGR0cPDAsLi37ttdealu41lAc2lA6ePXt2YFhYWPSYMWPCKysrBRhXHjg/P99m9OjR4VFRUQPnzJkT6O/v31R22OCvf/1rn8TERJcHH3ww0BDnpZdeGpaZmWn3xRdfeP/rX//yHTBgQNS6des6PRHoMAGQUu4GxgOjgQVAtJQyyQT3jgOypZS5Usp64FtgeotjpgOG0sMrgElCW35rOvCtlLJOSnkAyNZfTzHCoUOHqKuro6rK3yzN//BnC4C/vz/DhkFUy9SuG4mNjcXKyoqwMHDR/y8shMDNza1pECCogkAXGkMXgFeNfnXZDhKAYcOGAbBhwwawtiYtKoqrgAWVlXD4MG/6+FBcUqIlAAUFICW5+iUy+9vZYVdbq13ot99avX5jYyNPP/00Yzw8GAd8AKz47Te44w5wcID33gOa1QFwdoaqqm7bAvDPf/7zSL9+/eoyMjLSli5degQgKSnJ+dVXXz2ak5OTCvD111/npaampu/duzdt6dKlvseOHTvjQfHQoUMODz300PHs7OxUd3f3xi+++KLVRVFaKw/85JNP+o8fP74iLS0tfcaMGScKCgrsWp732muvFcTExFR/8cUXuYY4QVux8Lbbbiu65557CjMyMtImT55c2fJcc+tw9JcQ4n7gayllqv69pxDiJinl++d57wCg+dyXI8DIto6RUjYIIcqA3vrtf7Q4N+A84+kxMjMzATtKSlyJjDTPPZonAK+80jObv93c3CgvL8dL/9xRUNA9u0G6K8MqgA5FRdr8f1/fdo8PCgri8ssv58033+Thhx/mo7Iy3gYc3nkHJk5kf2UlnsXFMGyYVjCovJycnBz69OnD5S4uWgGhuDhISICKCnA9vft569atHDt2jJeHDYMDB/gjNBT5/fc89NBDMGcOfPUVvPJKUwLgZyi32QkJwJ130i8lBROXA6Z62TLOan7k4MGDqwYMGNBUVOcf//iH75o1azwAjh07Zpuamurg5+d3WpnggICAutGjR9cADBs2rDovL6/VKVGtlQfeuXOny48//pgNcP3115e7ubldUOPjjOkCmCelbKqZLKU8Acwzwb1ba3huWauxrWOMOVe7gBDzhRAJQoiEoiKjiz51a1oCEIJOJ8zWAuDh4cGQIUOIi4vDz6/7LAF8NgwJgGFcQHJy+8crnaymBiZNgjVrWt192hoA/v5G1a9euHAhx48f57nnnuP9ffsod3VFSAkvvICXl5f24WxYTfDYMXJycggJCeFiQyWuu+7SsuUdO8649rfffouXkxPh27fD9ddz2U03sW3bNq2r4r77oLoali37swvAkHV30y6A1jQvA7x69WrXLVu2uCYkJGRkZmamDRw4sKampuaMzzw7O7umzw5ra+um0r8ttVYe+GzKC3dFxsz/shJCCKn/SfV97Wc0c5yDI0DzNrW+QH4bxxwRQtgA7kCpkecCIKX8EPgQIDY29sL+2zKRjIwMnJyGU11tnhkABk0jonsoQwIQFKStw9LD/zi6nr17YeNG+OMPrQ9d34Rv0LQGQAdTAJsbO3YsEyZM4OWXXwag4rHHcKuthYsvxsvLi9TU1NMSgNzcXCZOnEh0Tg61QMPVV+NiZaXFc8UVTdetr6pi7/Ll/CskBJGSAgsWcL23N4sWLWLlypU88MADMH48/POfnNBXLPQ0LDfcCS0AZ/ukbgru7u6NVVVVbT7Enjx50trd3b3R1dVVt2fPHod9+/aZfLR9XFxc5ZdfftnrhRdeOLZy5Uq38vLysxqL5urq2ni255iSMS0AvwDfCSEmCSEmAv8G1png3ruAcCFEsBDCDm1Q308tjvkJmKv//npgoz4R+QmYrZ8lEAyEAztNEFOPkJmZiafnRKysYMAAS0fTfRlKAgsBQ4fCnj0dn6OYn5SS0tJSSNUXjHN0hKlTtQ96gy1buCElhb4+Ph0uAtTSwoULAa1ehP/ChfDSSwB/tgDop93UHzzI0aNHCQkJIbC+nmwg89gxLRFpPg7gyBFOhYURX1bGzJQUiI2FceOIiooiKiqKFStWaMc9+ywcPUrQli3Y2dnhWKnvUu6mYwD8/PwaR4wYURkeHh69YMGCM/6CZs6cWdbQ0CAiIiKinn76af8hQ4ZUtXad8/Hyyy/nb9y40S0qKmrgmjVr3L29vU95eHgY3Q0wc+bMk2vWrPGw1CBAY1oAnkAb/HcvWtP7/4CPz/fG+j79B9ASDGtgmZQyVQixBEiQUv4EfAJ8KYTIRnvyn60/N1UI8R2QBjQA90spL6i+F0vKzMxEypHExJzRzaiYkJubG3l5eYCWAHz4ITQ2GtWSrJjRunXrmDp1KkdvuAFfJydYvx4uuUQbqfrww1r/+1tv8SBwUXq6lhhcd53R158wYQL33Xcfo0ePbioZDFoCUFVVRY27O47AifR0pJSEhobSu6SEHUB1WhojLrkE/vUvyjIyeOSJJ3h+61Y8Kip4yNGRf65bh21sbNPUneuvv57nnnuOY8eO4TdpElx8MZds24Zf795/FgLqxl0Aq1atOtD8ffOSvI6OjnLr1q1ZrZ1nKPfbp08fmpcOXrJkSdMiDMaUB+7Vq1fj1q1b99va2rJ+/Xrnbdu2uTo6Op7R0ty8rG/z0sGDBw+u279/f9pZ/dAmZEw5YB3agNMPTH1zKeVaYG2LbQubfV8L3NDGuS8AL5g6pu6uoqKC/PwC7O3DmN5yzoViUoYuANAe6mpqtHFeqtXFsjZu3EhjYyOFGzbgGx2tZWfx8bBwITz/PAB18+bx9kcf8TfD3HwjuwBAmwHynn5EfnNe+tGgJTodfW1tqcjOBiA0MBC7w4fJFoKy9HSYPh351lu4DBzIi0AvtLnOUXfcga2+DLXBnDlzeP7553n++ed599134dln8b7mGj4XQpsV4OiorTyomEV2drbdrFmzQnU6Hba2tnLp0qV5lo7pbLTZBaB/wkYIkSyESGr56rwQFVPSBgBGUVfnQIuy5oqJubm5UVamrZk1dKi2TY0DsLz4+HgAvIuKKDN8sEdFwYoV/PTSS7w/fz45jzzCE8Dh2Fht/1kkAG0xJACGqYD1hw4BEG5rizh1inI/P9LS0mDCBL568kleAqwCArD/4Qe+LyrirbfeOuOakZGR3H///XzwwQfs3r2bsjFj2GNvz6iqKm2AzwcfqDoAZjRo0KC69PT0tMzMzLSUlJT08ePHV1s6prPRXgvAw/qv13RGIErn0BIA7ZNfJQDmFRgYSFVVFUeOHGHgwL7Y2WnjAGbPtnRkPVdDQwOJiYnMu+46+vzwA98dOcIs/b4dO3Yw49lnaWxsZExqKhI4sGQJ/fbvhyvPf7HRpgRAPw7A6tgxnJ2d6V1SAoCMiGDLli1ceeWVbNq0iclTp/LMf/8LQuDVznWXLFnCd999x4IFC9DpdKQ1NPD9d99xzcyZ5x2z0r212QIgpSzQj/j/REp5sOWrE2NUTEhLAMbg5SUJC7N0NN3b6NGjAdi+fTt2dtoywS1bAF599VVuvfVWC0TXM6WkpFBdXc0s/dzMzxMTSUhI4MSJE8yePZv+/ftzzz336CtZgm9IiDYuwOn8p7j37t0boGkqoP2JE4SEhCCytG7q2JtuwtfXl7KyMmbNmsVnn3122hiCtnh4ePDqq6+SkJBAeno6K1etUh/+ilHaHQMgpWwUQlQLIdyllCZZ/1+xrN27d2NndzsXXyxUy6CZDRkyBCcnJ7Zt28asWbOIjj7Ft99W8PPPO7G2nkzfvjrefPNNjh8/zscff2zSksxK63bu1CYLDbHRfvVl2dlx0UUX4ezsTH19Pdu2bWPEiBHU1tby3Xff0fcsRv935LQWAD8/XKurCQ0Nhf37wdOTGfPnM2PBgnO69i233EJBQQHjxo3j4osvNlnMSvdmzCyAWiBZCPEr0DSNQkr5kNmiUszi1KlTbN6cRH19CPqHU8WMbG1tiYuLa3qatLZOoqFhBPPn13HkCERFVTWtN//FF3l8+20kq1dr47YU84iPj6d37954HTsG7u5sTU9n1erV/Pzzz0ydOpWLLroIgGXLlvHGG2/gbMIBdL30a0IXFxej8/GhV2MjYUFBsHs3hIefV1+9EILHz7aUsNLjGbMOwBrg/4CtQGKzl3KBSUxMpKoqBlD9/51lzJgx7N27l8rKSvLyfgTgyJHpBAefIi3NFa2eFbz2mhsbN7a5DLxiIvHx8cTFxSFSUyEmBr8+fZg3bx4rV67kjjvuaDpOCIGHh4dJ721jY4OnpyfFxcXkS4kVcIWDA2zdCpMnm/RePcH5lAMGWLJkiU9FRUXTZ6AxJYKNtWDBgr5hYWHRCxYs6PvKK694v/vuu70B3n777d55eXm2priHKRhTDOhztMV/9gC7gX/rtykXmE2bNgGjsLaW6B90FDMbM2YMjY2NbNmyhZ07l+Likgc8x403vgPUExi4BGfn0ezfry0Os2GDJaPt3srLy0lLS2NkXJy2CJBhjeZOZFgMKFk/R3/c6tVaIZ8HHuj0WC507ZUDNsbSpUt9Kysrmz4DjSkRbKyvv/7aOzk5OW3p0qVHHn/88aIHHnigBOCrr77yOnToUJdJAIwpBnQVsBTIQVsIKFgIsUBK+bO5g1NMa+PGjTg7v8iAAUJNDe4ko0aNQgjBokWLqKkpYv36HF54YRMffLAb6E9JydU4OztRU1NLTIyDSgDMKDExESkl4yIioLQUYmI6PQZDAvDHyZNMAexTUrR1/LvxYj3m0rwc8Pjx48uXLl165P/+7/98f/jhh1719fXi6quvPvnGG2/kl5eXW02bNi2koKDATqfTiccffzy/sLDQ9vjx47bjx4+P8PT0bIiPj98fEBAwKCEhIb28vNxqypQp4XFxcZUJCQkuvr6+9b/88ku2i4uL3LJli9O8efOCnJycdCNHjqzcuHGje/OFhAAmTpwYVlNTYzVs2LCBjz32WEF6erqji4tLY3BwcH1KSorTbbfdFuLg4KBLSEhId3Fxsejy9MZ0AbwOXCqlnCClHA9cCrxh3rAUU6urq+O333ZRWzuU8eMtHU3P4eHhQXR0NImJifTq1Ytx48Zx++23U1ZWhhCfUlnpyPHjk7Gy+orp03Xs3q3KBpuLYf7/CMNgSwu2AGwwLENsZQV/+Uunx9EdtCwHvHLlSrfs7GyHpKSk9PT09LS9e/c6/fzzzy4rV6508/PzO5WZmZmWlZWVOmPGjPJnn332uI+Pz6ktW7bsj4+P39/y2m2VCL777ruD33vvvYN79+7NsLa2bvXDe+PGjdn29va6jIyMtHnz5jX933zHHXecMJQFzsjISLP0hz8YNwjwuJQyu9n7XOC4meJRzCQ+Pp66usGALS0WE1PMbMyYMaSkpDB9+nRsbW2ZOXMm999/PyNG1JKdDUePQkPDG0REXI6UgWzefFYrz/YsZWVaZSWDH38EQzW8Duzbt4+goCDcDuvr1lgoAVi/fj26mhp0VlZYzZwJoaGdHofJ3XlnP1JSTFoOmJiYapYtM7rI0Lp169y2bt3qFhUVFQVQXV1tlZGR4TBp0qSKZ555pt+9994bMH369LLJkydXdnSt1koEFxcXW1dVVVldfvnlVQBz584t/fXXX007UKSTGdMCkCqEWCuEuF0IMRdYBewSQswQQswwc3yKiWzcuBEhxiOE5JJLLB1Nz3KJ/g98pn5utrOzM2vXrmXp0vd58UWYO/c4kIZOtwMnJzUOoE2//AJeXvD229r7mhqYP7+p2E5HUlNTiY6O1vr/vbzA19eMwbbOy8uLmpoa6oCs11+Hd9/t9Bi6KykljzzySEFGRkZaRkZG2qFDh1IeffTR4sGDB9ft3r07bdCgQTXPPPNMwF//+tc+HV2rtRLBF3rp39YY0wLgABQChobjIrTlqacCElhpntAUU/rf//6HizEzK3wAACAASURBVMsbBAcL9LORlE4ya9YsXFxcuOqqq5q2GZKCyEi46SZP/v1vO5KTExk3bnZTAnDqFNh2meFCFpaZCTfeCA0N8Pe/w9y58PXXUFQEdnYgZbvT6BoaGsjMzGTKlCnaVAsLPP3Dn2sBODo6EnLffd3nL/gsntRNpWU54ClTppQvXrzYf/78+aXu7u66AwcO2NrZ2clTp04JHx+fhvvuu6/U1dVV9/nnn/cGcHZ2biwrK7Pq06fDfAAAb2/vRmdnZ92GDRucJ02aVPXll1+e9W9SFxeXxrKysi5TDsyYYkB3dHSM0rVt376dHTt2YWs7XPX/W4CtrS3T26m8ZGtrS0xMDHv27OGSS6pZt86Jyy/XsXmzFa+/Dg8+2InBdiFlZWUcPHiQwUFBMG2a9mG5ciXMmMEf113H4LQ0nADq6+HkSfD0bPNa2dnZ1NfXEx0VBf/6F9xyS2f9GKcxJABxcXHYdpcPfwtpXg544sSJZUuXLj2SmprqcNFFFw0AcHJy0n399dcHMjIy7J966qm+VlZW2NjYyPfff/8gwNy5c4unTJkS7uPjc6q1cQCtWbp0ad4999wT6OTkpBszZkyFq6vrWc0auO2224offPDBwL/97W9dYhBgt2zWaEtsbKxMSEiwdBid7oorrmDXLhtOnlzLihWgVgnteu6++26++eYbrKxiqKragY9PHWVlTtx1l1bUrSd66qmneOWVV9i4YAHjP/gA1q6FKVOomz4d+59+0g668UZYvhzS09sts7hixQpuuOEGktauZdBVV2l/qEaMGzC1n376ienTp/P000/zwgsXTjFTIUSilDK2+bZ9+/blDRkypNhSMVlCWVmZlbu7uw7g6af/v707j4+qPhc//nmyEZYkhIQESECWBJKwJYjsgoIo4AIWbV36K13EWrVWq7X2eu8t2lurL6u2Wmvr1atoW+vSUlQQBKqoIChIIEASwiIQCEkIWyBAlnl+f5wzIYQkTPYJed6v13nNnDNneebAZJ75rv/RIy8vL/iVV15p8dKP+ti4cWP08OHD+9b0mi9tAEwbtmrVKpYtW8a4cQ8BWP2/n5o0aRInT55k9OgwoDtPPPE28fHOD9v2at++fXg8Hv71gjsT+ahRACweO5Zy4OtOneC225zXDhyo81xbtmxBREgsLXU2tFIVQP/+/QGYOnVqq1zfNM5bb70VkZSUlJKYmDh49erVXX7961/ntXZMjeFLGwDThs2bN4+YmBjKy8eRnAwxDR42wzSnb3/720yfPh0RITo6muLiY3Tt2r4TgIMHDzJ48GDGnDpF2Y4dfLVtG6PHjuW1tWv5GxDQowdveutv8/PrPNeWLVvo378/oTt2OBtaKQEYMmQIe/fubdI5BkzLmTt37uGqXfvauvOWAIjISBG5T0SeFJFHReSbItKoZmQi0k1ElolIjvt4TuWdiKSKyOciskVENonIt6q89qqI7BKRdHdJbUw8F6pDhw6xfPly7rzzTrKzg7j44taOyNTG+8UfFhYGOPXflgAcJD4+nm+MH0+RCP/z2GOUlJSwdOlS3gE+Ki4+05LfhwRg8ODBsHmzkwVH1zXBbvOyL3/jL2pNANxuf18BvwA6Atk4/f8nAMtEZL6I9GngdR8CVqhqIrDCXa+uBPiOqg4GpgG/E5GqfS5/pqqp7pJew/HtXl6eUzqVmDiQAwfAx8auphWFhIQQGhrKsWNWAnDw4EGio6MJPnQIYmN5//33efLJJzl58iRjxoyhqKiIiogICAykdO/eyoF+qistLWXbtm1nugC20q//C5DH4/HYnKJ+zP338dT2el0lAJ2B8ao6W1UfU9WXVPUPqnqPql6MMxpgYgPjmgl45xOYD8yqvoOqblPVHPf5fpzkw8bLrId891dRly69OH26Vbo9mwYIDw+3BIAzCQAFBUSlpBAeHs4jjzxCREQEN954Ix6Ph0NHjkBMDDmffca4ceMqk96qcnJyKC8vd3oAbN1qCUDT2VxYWBhhSYB/8ng8UlhYGAFsrm2fWtsAqGqdbY8b+as7VlXz3PPkiUidNdMiMgoIwZmPwOvXIvLfuCUIqnq6EfFckLwJQEBALwB69GjNaIyvIiIiOHbsGL16td8EoLS0lOLiYicByM8neOBA7r77bh577DFmzJhBXFwcAIWFhXSPjYX8fDweD+vXr+eapCRISKg81xZ32N3Ubt3g+HFLAJpIeXn5bQcOHHjpwIEDQ7AG5f7IA2wuLy+/rbYdak0AROTZus6sqvfU9bqILAdq+sp5uK7jajhPT+B1YI6qeosyfgEcwEkKXgR+Djxay/G3A7cD9OnT0BqLtsmbAHg8TsGJlQC0Dd4SgJQUKClxurmHhLR2VC2rqKgIgKhu3aCgAGJjuffee1m8eDG33Xbm71lBQQEpsbF02L0bgH2LFsG118IHH1ROsbt582YCAgJavQfAhebiiy8uAK5r7ThMw9WVta13l1BgBJDjLqnAeQc/UNUrVHVIDctCIN/9Yvd+wdc4t4CIhAOLgP9U1TVVzp2njtPAK8CoOuJ4UVVHqurI7u1sxq38/HwCAwMpKQkHrASgrQgPD69sBAjO8PftzcGDTvfy2LAwZ8jfmBi6d+/Ohg0bmDx5MjFud5bCwkKIjaXLiRMAlK5x/0wsXVp5rq+++oqEhARCsrOdDZYAGAPUkQCo6nxVnY9Tz3+5qj6nqs8BU3CSgMZ4F5jjPp8DLKy+g4iEAAuA11T17WqveZMHwWk/UGsdR3uWn59PbGwsBQXOP7MlAG1D1TYA0D6rAbwJQE/v8L7Viq+8yXxBQQH06EGk++s+aLs7b9nHH+PxeHjggQdYtGgR354wAZ58EtLSsLGwjXH4Um/TCwirst7F3dYYjwNTRSQHmOque7scvuTu801gIvDdGrr7/VVEMoAMIBr4n0bGc0HyJgD5+RAYaH/32gpLAM4kAJWNg6oNYBEVFYWIUFhYiCcmhg5AXOfOxB93JnrTjRv50U038dRTT3HfHXfwnxs2OPMIvPlmy70JY/ycLwMBPQ5sEJGP3PVJwLzGXFRVi3BKEqpvXwfc5j7/C/CXWo6f3JjrtxfeBODAAecHVIA102kTvI0ALQGAyLIyZ0O1BCAoKIhu3bpRUFBAcUwMEcD148aRtGwZp6KiCC0qIu/tt3nooYd47OBBJD0d3nsPEhvaccmYC895vxJU9RVgNE5x/AJgrFs1YPxc9QTAtA3eEoCICGeejvacAISfPOlsqOE/cExMDIWFhRS6me01w4bRH0hPSaE0MJArAgP5j9mzkf/7P7j3Xrj66pYK35g2wZeRAAW4AhjuNuALcbvlGT+mqhQUFFRWAVj9f9sRHh5OeXk5oaGngPabAISHhxN06JCzoYYGvN27d6egoIB95eUADD5yhEDg4yNH+FyVmRERhP3+9xAaCg/VNNaYMe2bL4XCfwTGAje768VAO52frO04cuQIpaWllSUAlgC0HeHhTq+NgIBjQPtNALxjANC1K3TocM4+3hKAXSUlAHTf7LQFfjMjgxUeD30OH4a//c2Z9c8mwTDmHL4kAKNV9S7gFICqHsbpf2/8mHcMgO7dY73dqE0b4U0AysuPEhjYzhOAgoJav7y9JQA7jx6lAghJd8Ym2wbs6dcPUXUShwceaLnAjWlDfEkAykQkEFAAEelOHWMLG//gTQA6d46nrMxKANqSiIgIgHNmBMzMzOSll16q48gLx1kJQC3Za0xMDIcOHWJ3bi5FAQHI6dOcjI2lBLjkrrucbi/33GPZrzG18CUBeBan8V+MiPwa+Ax4rFmjMo3mTQDcIRPsb2Ab4i0BOHbsGJGRZxKA3/3ud8ydO9cZ/OYCd1YVQB0lAKrKpk2bOOJWEYQOH85f//pX5v74x7BjBzxmf6qMqY0vvQD+CjwI/AbIA2ZVH5jH+J/qwwBbCUDb4U0Aqk8JvHXrVgA+++yz1gqtxfhSBeAdDXDLli2c6NIFAElO5pZbbiEkJMRpO2B9X42plS+9AF4GQlX1eXc2wEwRmdf8oZnGyM/PJyAggJMnneJkSwDajqolAN4EQFUrE4BPP/20NcNrdidPnqSkpISYyEgoKqq1+Mo7GmBZWRmlkZHOxuTklgrTmDbPl/T4KuBVEflOlW02AYSfy8/Pp3v37hQWOv/EVgXQdtSUABQWFnLI7RL3ySeftGZ4zc47EVCct+V/HVUAXurdJympWWMz5kLiSwJQgDMk740i8ryIBAE2/7OfqzoIkLc01LQNNSUA3l//o0ePZsOGDRQXF7dmiM2qch6AwEBnQx2NAL2kb19nvGsrATDGZ74kAKKqx1T1WqAQWAlENG9YprGqjwIolrK1GSEhIYSGhtaYAPzwhz/E4xlO377BZGW1cqDNpHIeAHVGQqytBKBbt26I+x/7xLe+BWvWWH9/Y+rBlwTgXe8TVZ2H0xjw62aKxzSRqhMBWf1/21N1QqCSEsjIyCYsLIwbbrgBkRkcOhTKb397/vN4PB5eeeUVTp8+3fxBN9KCBQvYs2cPoYsW8SOgmzfmWkoAAgMDnYaCQM8BA2DkyBaK1JgLgy+9AH5Zbf19m4zHv6nqWSUAlgC0PeHh4ZW9AAAyMvaSkpJCWFgYXbs6H7/XX3d6ydXls88+4/vf/z7//Oc/mznixjlx4gSzZ8/mRz/6EYP/9jf+CPR84gnnxTp+1XvbAcTFxbVAlMZcWGpNAETkM/exWESOVVmKReRYy4Vo6qu4uJhTp05VlgBYA8C2p/qUwFlZB0hJSQGgoiIVkfWUlSnPn2dQbm/VgffRX23btg1VZdnixYQXFvIZOCP5dekCbpuImsTExNClS5fKdhPGGN/VmgCo6gT3MUxVw6ssYapqnzY/dmYY4B4UFFgJQFtUfUrgoqJyUlJSKCqCY8e6ofomF1+8nz/+0akiqE1mZiYAW7ZsZeJEeO21Fgi+AbKzswEYJEKgKq916oRs2QIffVRnA5bExESSreGfMQ1SVwlAt7qWlgzS1I83ATh9uj8eD/Tv38oBmXqrXgIAXUlJSeGrr5y1Pn0OUlj4EEVF8MwztZ/HmwBkZBTx6afw6qvNGXXDZWVlISLcN20aAPlRUdC793nr9Z955hmWLl3aEiEac8Gpqw3AemCd+1h9WdeYi7pJxDIRyXEfI2vZr0JE0t3l3Srb+4nIWvf4N0XEJieq4ssvvwQgN9f5ZTRlSmtGYxqitgRg/Xpn7Ze/vJbdu//CmDG7mTcP1q6t+TzeBGDnzo4ArFpVd4mBV2lpKR5Py035kZWVRb9+/bhx8GA8wLGePX06rnPnzkRG1vjnwxhzHnVVAfRT1f7uY/Wlsb8pHwJWqGoisMJdr8lJVU11l6qDDz0BPOMefxj4QSPjuaAsWrTI/bLoxsCB0KdPa0dk6qt6I8CQkBj69OnD+vXQrx9897szGTp0KIWFs4mLU26+GY4ePfscxcXF5ObmkpycjMfjDJBTWgq+DCQ4ceJErr76akpLSwHweGDfvqZ8h2fLzs4mKSmJsNxcjkdHM/cnP2m+ixljAN+6ASIikSIySkQmepdGXncmMN99Ph+Y5euB4nT8nQy805DjL3TFxcV88sknXHXVdaxcCVOntnZEpiG8JQAREU5f+OjoRAICAli/Hi6+GAICAnjkkUfYsWM9c+d+zJ498OijZ5/DW68+e/ZsIIXOnUsJCYHly+u+tqqyceNGlixZwty5c1FV7rnHqUoqKDh738OH4Re/gD/9qeHv1ePxkJ2dzaBBg2DrVsJHjeKWW25p+AmNMT7xZS6A24BPgKXAI+7jvEZeN1ZV8wDcx9r6+YSKyDoRWSMi3i/5KOCIqpa767lArX2AROR29xzr2sMsasuXL6esrIw+fb5FSYklAG1VREQE5eXlqJ4AyoiJGcihQ7Brl5MAAFx77bUEBwdz4sQyJkyA1avPPoe3+H/WrFnAYLp338/48bBsWd3XPnz4MKdOnWLQoEG89tprfOtbC3j+eaf04KOPzuz35z+fIiFBefxxuOsuKqsn6mvv3r2cPHmS5IEDITsb3N4Oxpjm5UsJwE+AS4Ddqno5kIYzImCdRGS5iGyuYZlZj/j6qOpI4BbgdyIygJqHIdbaTqCqL6rqSFUdWXXs8AvVokWLiIiI4MCBoQQGwmWXtXZEpiG83drWrPkcOEK3bv3ZsMF5zZsABAUF0a9fP7Zv387gwbB1K2iVT0JmZiZBQUEMHToMkSEEB2/jiitg48Zzf8lXtc8t63/00UeZPPlHvP32lYwbp4SHw/Ll5dxxxx0kJEzgjjtCCA3dzcqVTlfT226DsrL6v1dvScXw8HA4fdqG8zWmhfiSAJxS1VMAItJBVbOAQec7SFWvUNUhNSwLgXxxJ6p3H2v8c6Sq+93HncDHOMnHQaCrOycBQDyw34f3ccFTVRYvXsyVV17Jv/8dyOjREGGDNrdJ3gTggw8+AI7g8cTz4ovOayNGnNkvISGBnJwcUlLg2LGz6+kzMzNJSEigsDAY1XBKStZXlgitWFH7tffvdz5OcXFxHD/+E6CcZ57J49JL4YMPTvHnP/+Z4OAbgADy8q4jLGwDzz8P6enw9NP1f69Z7pjGiRUVzgZLAIxpEb4kALki0hX4F7BMRBbS+C/cd4E57vM5wMLqO7jtDjq4z6OB8cBWVVXgI+CGuo5vj9LT08nLy2PixFmsW2fF/21Z1QQgKOgEH3/cmbffhnvvhaioM/slJCSwfft2UlKcn/5Vx/vJysoiOTmZLVuc9YKCjxg+vILIyLqrAbwlAL169aKkpBewngMH1nHZZbBvXxdEehEffzf9+lUQHZ3PHXfcwXXXVTBrltMO4eTJ+r3XrKwsunbtSldv9mIJgDEtwpehgK9X1SPuPAD/BbxM4xvdPQ5MFZEcYKq7joiMFJGX3H2SgXUishHnC/9xVfX+efs58FMR2Y7TJuDlRsZzQfjwww8BCAubgap1/2vLvAlAVlYWAwdu5dpr4auvzu3zn5iYyPHjx+ne3amV8yYAZWVlbN++naSkpMoEoKxsA3v3fs1ll8HKlbVfu2oCcPhwZ2AP6enpXH6583qPHrezcmUQs2cH8swzT/PFF1/wv//7v9xxh9PFsGo7AV94GwBKVhb07GlTVxrTQurTC2AYUIzT6G5IYy6qqkWqOkVVE93HQ+72dap6m/t8taoOVdXh7uPLVY7fqaqjVDVBVW9UVf+f6aQFbNq0iT59+pCT05XAwDN1xabtqTq07Q9+cIB334XU1HP3S0hIAODIkW1ER1P5Zb99+3bKy8tJTk5m61bo2rUMOEhmZibjx8POnXDgQM3X3rdvH9HR0QQEdCAvL4CoqBLS09MZPlwROcqRIz+hrAyuvx5uueUWxo0bx7PPPsukSdCpEyxeXL/3mpWVRVJSkpO9WANAY1qML70AfgVsAp4DnnIXH+YhMy0tMzOT5ORk1q2DIUOcP8ambYqo0nhj/Pjxte7nTQCcaoAzJQDeHgDeKoDBg53tW7ZsYcIE5/mqVTWfc9++fcTFxbF/P+5IkkGkp6ezf/9eVFdy8mRXYmNhzBgQEWbPnk1mZiaFhXu54gpYtOjsxoh1KS4uZv/+/SQnJkJmphX/G9OCfCkB+CYwQFUnqerl7mKzAfoZj8fj/pJyEgCbGbVt85YAhIaGkpaWVut+ffv2JSgoiJycHAYPdkoAVGHVqlUEBweTlOQkAMOGBdOnTx+++uor0tIgNBQ++6zmc3oTgD17nPUhQyLYtWsXy5Ytw6mNg5kzIcD96zHNHb536dKlzJgBX3/tfJf7YtOmTQCMr6iA48dh0iTfDjTGNJovCcBmwCrl/NyePXs4efIkMTGjKCqyBKCtCwsLA2DUqFGEhNQ+0nVQUBB9+/atLAE4ehT271f+9a9/MWXKFI4c6cyxY04JwJgxY1i7di0hITB6dN0lAL169apMAMaNiwfgpZdeIihoGaGhyre/fWb/5ORk4uPjWbJkCTNmONt8rQZYuHAhwcHBXPL1106RlfcExphm50sC8Btgg4gsFZF3vUtzB2bqxzvda3m5U1F8ySWtGY1prA4dOtC7d2+mT59+3n3P9ARw1t9/fxc7d+7k+uuv5+23nW3jxsHo0aPZvXs3eXl5jB/vNCo8ceLsc5WWllJQUEBcXBx79zrbJk9OBGDNmjUMG9aB4mLh0kvPHCMiXHXVVSxfvpyePcsZNsypBjgfVeWdd95h6uTJdFi0CK6+2uqtjGlBviQA83HG3n+cM20AnmrOoEz9eet8Dx68iJAQpw2AaduysrL42c9+dt79EhMT3bEAnIr3f/1rGyLCjBkz+d3vYOJESEtzSgAA1q5dy/jxUFEBX3xx9rkOuC0DvVUAUVHQv38sPdw5pS+55BKCgjjHVVddxdGjR/niiy+YMcOpXqg+N0F16enp7Nq1izuHDnVGJrrhhroPMMY0KV8SgIOq+qyqfqSqK71Ls0dm6iUzM5Po6Gi2bOnEsGHQoUNrR2Qaq1OnTgQGBp53v4SEBIqLixEppFs3+OKLE4wbN45PP41lzx544AFnv7S0NIKCgli7di1jx4LIudUA3i6A3gTAO5FUaqq3ZKnmoqUrrriCgIAAli5dypQpUF4O684zZ+g777xDYGAgk4uKoGNHpwTAGNNifEkA1ovIb0RkrIiM8C7NHpmpl8zMTJKSUli3zor/25szPQFyGDDgFIcOJXPppd/lySchKenM92rHjh1JTU1lzZo1REY67QKqNwSsngD07u1s9zZEHFlL45LIyEhGjRrFkiVLGDbM2ZaRUXvMqso//vEPJk+aRMcPPnDq/jt3btgNMMY0iC8JQBowBngM6wbol1SVzMxMevWayLFj1gCwvUlMdOroc3JyiI39EBjI44/fxoYNcP/9Z1rrg9MO4Msvv6SiooKJE50hgW+//cz4AbWVAMyZM4ef/vSnDKmjbmny5MmsW7eOiIjTxMTUnQBs3bqV7Oxs7h8wwBmQ4MYbG3MLjDENUENt3hkiEgC8oKpvtVA8ph5UnRHdfv3rUg4fXsH69c5kR5YAtC8XXXQRgYGB3HfffRw5coRx427kyivfIjubs1rrg9MO4Pnnn2fLli3MmzeM0lJ4/XWYP9+ZiG/fvn2EhIQQHBzF0aNnEoBBgwbx1FN1N/1JSUnB4/GwY8cOhg5NqTUBqKio4MEHHyQ8MJArFi+GoUNh9uwmuBPGmPqoMwFQVY+I3A1YAuCHrr8eFi6EyEgBCjh8OIV+/WwwtfYmJCSE1NRUcnNz+cMf/sDcuXOprefg6NGjAWfY6Pz81/F4DrFixcuMH+9M5uPtApib60y66U0AfDFokDNHWHZ2NkOHpvDii85AQgHVyhkffPBBFi9ezPpp0whcsgTeeIMaWxYaY5qVL5+6ZSLyAPAmUNlpyDt8r2lZhYWFTJw4kb59L2fJkj9y553lDBz4Kvfe+0PS0/cQH98bqWnCZHNBW7lyJYGBgYSGhta5X0JCAt26dTurd8Gjj/4B6MjOnecOAlSfBGDgwIGA03thyBBnXoCdO8FtogDAK6+8wtNPP80jt97KiLfegu98h7P6FBpjWowvCcD33ce7qmxToH/Th2POZ8WKFWRlZbF7tzPV3xtvTKJXr6N06dKF+Ph4+/Jvpzr72IBORPjud7/Lxo0bGT58OE8//TQlJfuIiEhgxw5nKuC0tLQGJQDh4eH06tWL7OzsyomoNm8+kwBs3LiRO++8kylTpvCfx487wxE+8UQ93qUxpin5MhtgvxoW+/Kv5tVXX2WRL6OfNNLq1avp3LkzM2Y8Q1TUKSZOjCEzM5O0tDTEvv2ND5566imWL1/ODHfUvf379zFgAOzcqWeVAAQFgdv932eDBg0iKyuLwYOdbobedgDHjh3jxhtvJDIykrfuu4+AhQvhwQfrfwFjTJM5bwmAiAQDPwImups+Bv6sqmXNGJdf+eCDDzh69Cg33XRTrfv86le/onfv3lzdzH2ZV61axahRY/j440CuuSaQV19dQF5eHsHBwc16XXPhiYuLAyA3N5f+/SE93UNJSQm9evVi40aIiwMfhiE4S1JSEm+88QadOin9+0tlAvDjH/+YHTt28NG//023hx92vvjvu6+J35Expj586Qb4AnAx8Ed3udjd1m786U9/4tFHH61zn4KCAnJycpo1juPHj7Nx40YGDPgGRUVwxRXO9p49exIdHd2s1zYXnuoJwO7dAgTQt2/fs7oA1segQYM4cuQIhYWFDB3qlACUlpby5ptvcscddzDx6FFn9KF586zfvzGtzJcE4BJVnaOq/3aX7wHtaqiZtLQ0srOzKSkpqfH1kpISjh8/zv79+zlRfXD1JrR27VoqKirwTsborWc1piHCwsKIiIhg3z6nCqCsLACIo3///uzc2fAEAJyGgEOHQk4OrFu3mdOnT3PZZZfByy/DwIHw/e/XfSJjTLPzJQGoEJEB3hUR6Q9UNOaiItJNRJaJSI77GFnDPpeLSHqV5ZSIzHJfe1VEdlV5LbUx8ZxPamoqHo+HjFo6NhcWFlY+3759e7PFsXr1akSEXbsGMHgw9OzZbJcy7URcXFxlCYCjPx06DCA3t2HjSSQlJQFOV8AhQ5z5Bt57z/lMjBo1Ct55x5kq0KqsjGl1viQAPwM+EpGPRWQl8G/g/kZe9yFghaomAivc9bO4cw+kqmoqMBkoAT6sGpf3dVVNb2Q8dfKOg56eXvNl8vPzK583ZzXAqlWrSEkZweefB1cW/xvTGPHx8ezbt68yAejUaSibN0cAMH58/c/Xp08fQkND3bEAnG0rV54gNjaWPn36OF/8AwbUfRJjTIvwpRfACiARuMddBqnqR4287kycWQZxH2edZ/8bgA9UteYy+GZ20UUX0bVr11oTgIKCgsrnzZUAVFRU8PnnnxMd/RNOnrR5U0zT8JYA9OkDIhWEh6exapUzK29qA8rVAgICSExMoSAcJgAAEVJJREFUJCsri0GDnFkp16+fxMiRY6yXijF+xpcSAHAa/g0BhgPfEpHvNPK6saqaB+A+xpxn/5uAN6pt+7WIbBKRZ0Sk1rnvROR2EVknIuuqFtXXh4iQmpp63gQgKCio2RKALVu2cOzYSbZsuZ5Ro7ASANMk4uPj3SmAywkK2kdw8CBWrYJRoxpeSp+UlER2djYBAfCzn52gtLQ/oaHfa9K4jTGNd94EQERex5n8ZwJO479LgPPWDorIchHZXMMysz4BikhPYCiwtMrmXwBJbizdgJ/XdryqvqiqI1V1ZPfu3etz6bOkpqayadMmKirObf7gTQDS0tLOSQBUYdEiOHmywZcG4O9//zvwAw4e7MKjj2ID/pgmERcXh8fjYf/+/ZSXb6OkJIGNGxtW/O81aNAgdu3axenTp+nZcw2QzuefT6W8vMnCNsY0AV9GAhwJpKiq1ufEqlrrb1QRyReRnqqa537BF9S2L/BNYEHVcQe8pQfAaRF5BXigPrE1RGpqKiUlJeTk5FQ2dPIqKCigS5cuDBs2jPfff/+s1zZsgGuucXo8zZgBjz129tCovtixYwe//e0f6NTpa9LS4MorG/tujHHEx8cDTg8T1SKKipyP7YQJDT9ncnIyFRUVrFixwi01W8v+/Qt5/XX4nhUEGOM3fKkC2Aw09XBd7wJz3OdzgIV17Hsz1Yr/3aQBcSoVZ7kxNqu6GgLm5+cTExNDYmIi+fn5HDt2rPK1oUPhww+dWdkWL4YHGpCq3H///YjcTElJN/v1b5qUdyyATz75BNgJOP+/xo5t+DlnzpxJcnIyc+bM4b333mPgwGxGjoT165sgYGNMk/ElAYgGtorIUhF517s08rqPA1NFJAeY6q4jIiNF5CXvTiLSF+gNrKx2/F9FJAPIcOP7n0bGc17JyckEBwfXmAAUFBRUJgBwpitgRUUFwcEwdSr86U/Or58PP3QmSfHVhx9+yMKFC0lKupdeveDyy5vk7RgDnCkBcBKAHYDTcC8iouHn7Ny5MwsWLOD06dOsWbOG0aNHsXIl/OEPTRCwMabJ+JIAzMP5lf0Y8FSVpcFUtUhVp6hqovt4yN2+TlVvq7Lf16oap6qeasdPVtWhqjpEVb+tqscbE48vQkJCGDJkiE8JQE5ODvPnzycsLIwnnniist3ArFlOW4APPzznFLV6+eWX6dEjjtzcJK680n79m6YVFRVFhw4dyMjIICBgN9C4+n+vQYMGMX++09FnwoQJdOrU+HMaY5pWrQmAW7yOqq6saam6T3uRmprKhg0bqN4cwpsADHD7N69Zs4b777+fDh068NBDDzFhwgSKioqYOBEiI2HBAt+vuWnTJgYNuplDh4SpU5vy3Rjj9HCJi4tDVendu4QRI+Cb32yac19//fVkZ2fzPav4N8Yv1VUC8JGI/FhEzhoQVERCRGSyiMznTD1+u5CamkpBQYHbbcrh8XgoLCwkNjaWTp06ER8fz3PPPcfhw4dZuXIlf/nLX1izZg2vv/46wcFOg8D33uO8LaJLS6G4+CTbtm0jIOAqwLr+mebhbQeQkNCL9eubtppp4MCBNlGVMX6qrgRgGs6Qv2+IyH4R2SoiO4EcnIZ5z6jqqy0Qo9+oqSHgoUOHqKioICbGGcogMTGRiooK7rrrLoYNG8att95Knz59+PzzzwGnGuDwYfj005qvUVQEv/wlxMbCVVeV4vEo+fnDSUuDmPONlmBMA3jbAfTvb7N8G9Oe1JoAqOopVf2jqo4HLgKmACNU9SJVndvcw+/6o+HDhwNnJwDeMQC8CcCIESPo0aMHjzzySOU+48aNY/Xq1QBcdRWEhtZcDXDihNMA69FHISkJPv88AphHTk60df0zzcYSAGPaJ59GAlTVMlXNU9UjzR2QP4uIiKB///5s2LChclv1BOCxxx4jKyuLyMgz8xuNGzeO3Nxc9u7dS+fOTj/+BQvA4zZtPHToELfddhtPPrmWAwec+VJWr4bExHTgvykrs/p/03y8VQCWABjTvvg6FLBxVR8SuHoCEBISQkS1PlRj3U7V3mqA2bMhNxe+/NJ5fdGiRbz88ss88siniJQyYMA2RKBnz3mEhBygY8emaZltTE28vVdSUlJaORJjTEuyBKCeUlNT2b59O8XFxcCZmQBj6qigHz58OB07dqysBrj2WggKgn/8w3k9IyODkJAQevf+HgEBa/jNb/4LVWXr1lVcc83z/POfTrWBMc1h+vTpbNy4kSFDhrR2KMaYFmQJQD2lpqaiqmRkZABOCUBAQABRUVG1HhMcHMyoUaMqE4DISJgyxUkAVJ0EIDFxHHv3RjF6dDELFiwgIyODgwcPMmlSd6ZNa5G3ZtopEWHYsGGtHYYxpoVZAlBP1XsCFBQUEB0dTWBgYJ3HjRs3jg0bNnDSnRVo9mzYuRM2boTNmzfTrds3APjxj1MoKyvjpz/9KQBDvZOqG2OMMU3IEoB6io+PJyoqqrIhoHcQoPMZO3Ys5eXlrFu3DnC6AwYEwF/+cpLc3FxOn55IeDjccEM/Lr30UlasWAFYAmCMMaZ5WAJQTyJyVkPA+iQAQGU1QPfuMGkS/P3vAP3YsyeByy5z2gb88Ic/BKBXr15ER0c3x9swxhjTzlkC0ACpqalkZGRQXl5eORPg+URHR5OSklL5yx7gnnsgLy8EyOHAgc6VI/3Nnj2bqKioyuoGY4wxpqlZAtAAqampnD59mgcffJADBw4QGxvr03HTpk1j5cqVnDhxAnCqAW699T/p0OH3jBihzJrl7BcaGsqyZct47rnnmustGGOMaecsAWiA6667jmuuuYZnn32WEydO0LNnT5+OmzZtGqWlpaxceWZ24127PuOSSxawfr3Qu/eZfdPS0mxgFmOMMc3GEoAGCA8P57333mP//v387W9/Y+7cuT4dd+mll9KxY0eWLFkCUNmd0PpfG2OMaWmtkgCIyI0iskVEPCIyso79polItohsF5GHqmzvJyJrRSRHRN4UkZCWifxsMTEx3HzzzXTr1s2n/UNDQ7n88ssrE4B9+/Zx9OhRa+lvjDGmxbVWCcBm4BvAJ7XtICKBwPPAdCAFuFlEvGOVPoEzG2EicBj4QfOG23SmTZtGTk4OO3bsqBxMyBIAY4wxLS2oNS6qqpngdKmrwyhgu6rudPf9OzBTRDKBycAt7n7zgXnAC80Vb1OaPn06AM8++2zlWAKDBw9uzZCMMca0Q62SAPgoDthbZT0XGA1EAUdUtbzK9rgWjq3BEhISGDBgAM8++yyRkZG88MILPlchGGOMMU2l2RIAEVkO9KjhpYdVdaEvp6hhm9axvbY4bgduB+jTp48Pl21+v/3tb9m8eTN33303Xbt2be1wjDHGtEPNlgCo6hWNPEUuUKVjHPHAfuAg0FVEgtxSAO/22uJ4EXgRYOTIkbUmCi1p1qxZzPJ2+jfGGGNagT93A/wSSHRb/IcANwHvqqoCHwE3uPvNAXwpUTDGGGOMq7W6AV4vIrnAWGCRiCx1t/cSkcUA7q/7u4GlQCbwlqpucU/xc+CnIrIdp03Ayy39Howxxpi2TJwf1O3DyJEj1TsbnzHGGN+IyHpVrXXMFtM2+XMVgDHGGGOaiSUAxhhjTDtkCYAxxhjTDlkCYIwxxrRDlgAYY4wx7VC76gUgIoXA7gYeHo0zCFFb0dbihbYXc1uLF9pezG0tXmh7MfsS70Wq2r0lgjEtp10lAI0hIuvaUjeYthYvtL2Y21q80PZibmvxQtuLua3Fa5qOVQEYY4wx7ZAlAMYYY0w7ZAmA715s7QDqqa3FC20v5rYWL7S9mNtavND2Ym5r8ZomYm0AjDHGmHbISgCMMcaYdsgSAB+IyDQRyRaR7SLyUGvHU52I9BaRj0QkU0S2iMhP3O3dRGSZiOS4j5GtHWtVIhIoIhtE5H13vZ+IrHXjfdOdBtpviEhXEXlHRLLcez3Wn++xiNzn/n/YLCJviEiov91jEfk/ESkQkc1VttV4T8XxrPs53CQiI/wk3ifd/xObRGSBiHSt8tov3HizReSqlo63tpirvPaAiKiIRLvrrX6PTcuxBOA8RCQQeB6YDqQAN4tISutGdY5y4H5VTQbGAHe5MT4ErFDVRGCFu+5PfoIz1bPXE8AzbryHgR+0SlS1+z2wRFWTgOE4sfvlPRaROOAeYKSqDgECgZvwv3v8KjCt2rba7ul0INFdbgdeaKEYq3qVc+NdBgxR1WHANuAXAO5n8CZgsHvMH92/Jy3tVc6NGRHpDUwF9lTZ7A/32LQQSwDObxSwXVV3qmop8HdgZivHdBZVzVPVr9znxThfTHE4cc53d5sPzGqdCM8lIvHA1cBL7roAk4F33F38Ld5wYCLwMoCqlqrqEfz4HgNBQEcRCQI6AXn42T1W1U+AQ9U213ZPZwKvqWMN0FVEerZMpI6a4lXVD1W13F1dA8S7z2cCf1fV06q6C9iO8/ekRdVyjwGeAR4EqjYEa/V7bFqOJQDnFwfsrbKe627zSyLSF0gD1gKxqpoHTpIAxLReZOf4Hc4fH4+7HgUcqfKH1N/uc3+gEHjFrbZ4SUQ646f3WFX3Ab/F+XWXBxwF1uPf99irtnvaFj6L3wc+cJ/7bbwich2wT1U3VnvJb2M2Tc8SgPOTGrb5ZdcJEekC/AO4V1WPtXY8tRGRa4ACVV1fdXMNu/rTfQ4CRgAvqGoacAI/Ke6viVtvPhPoB/QCOuMU71bnT/f4fPz6/4iIPIxTHfdX76Yadmv1eEWkE/Aw8N81vVzDtlaP2TQPSwDOLxfoXWU9HtjfSrHUSkSCcb78/6qq/3Q353uL79zHgtaKr5rxwHUi8jVOlcpknBKBrm5xNfjffc4FclV1rbv+Dk5C4K/3+Apgl6oWqmoZ8E9gHP59j71qu6d++1kUkTnANcCteqZvtb/GOwAnMdzofgbjga9EpAf+G7NpBpYAnN+XQKLbejoEp1HPu60c01nc+vOXgUxVfbrKS+8Cc9znc4CFLR1bTVT1F6oar6p9ce7nv1X1VuAj4AZ3N7+JF0BVDwB7RWSQu2kKsBU/vcc4Rf9jRKST+//DG6/f3uMqarun7wLfcVuqjwGOeqsKWpOITAN+DlynqiVVXnoXuElEOohIP5yGdV+0RoxVqWqGqsaoal/3M5gLjHD/j/vlPTbNRFVtOc8CzMBp3bsDeLi146khvgk4xXSbgHR3mYFTr74CyHEfu7V2rDXEfhnwvvu8P84fyO3A20CH1o6vWqypwDr3Pv8LiPTneww8AmQBm4HXgQ7+do+BN3DaKJThfBH9oLZ7ilM8/bz7OczA6eHgD/Fux6k39372/lRl/4fdeLOB6f5yj6u9/jUQ7S/32JaWW2wkQGOMMaYdsioAY4wxph2yBMAYY4xphywBMMYYY9ohSwCMMcaYdsgSAGOMMaYdsgTAmFYgIvNE5IHWjsMY035ZAmCMMca0Q5YAGNNCRORhd1745cAgd9tcEflSRDaKyD/ckfvCRGSXO7wzIhIuIl97140xpilYAmBMCxCRi3GGPU4DvgFc4r70T1W9RFWH40zj/AN1pnT+GGe6ZNzj/qHOmP7GGNMkLAEwpmVcCixQ1RJ1Zmr0zicxREQ+FZEM4FZgsLv9JeB77vPvAa+0aLTGmAueJQDGtJyaxt1+FbhbVYfijN0fCqCqq4C+IjIJCFTVzS0WpTGmXbAEwJiW8QlwvYh0FJEw4Fp3exiQ59bv31rtmNdwJnKxX//GmCZnkwEZ00JE5GHgO8BunFnZtgIngAfdbRlAmKp+192/B7AL6KmqR1ojZmPMhcsSAGP8lIjcAMxU1f/X2rEYYy48Qa0dgDHmXCLyHDAdmNHasRhjLkxWAmCMMca0Q9YI0BhjjGmHLAEwxhhj2iFLAIwxxph2yBIAY4wxph2yBMAYY4xphywBMMYYY9qh/w/p3mdQeidt5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104ad4588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot everything - the original series as well as predictions on training and testing sets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot original series\n",
    "plt.plot(dataset,color = 'k')\n",
    "\n",
    "# plot training set prediction\n",
    "split_pt = train_test_split + window_size \n",
    "plt.plot(np.arange(window_size,split_pt,1),train_predict,color = 'b')\n",
    "\n",
    "# plot testing set prediction\n",
    "plt.plot(np.arange(split_pt,split_pt + len(test_predict),1),test_predict,color = 'r')\n",
    "\n",
    "# pretty up graph\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('(normalized) price of Apple stock')\n",
    "plt.legend(['original series','training fit','testing fit'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** you can try out any time series for this exercise!  If you would like to try another see e.g., [this site containing thousands of time series](https://datamarket.com/data/list/?q=provider%3Atsdl) and pick another one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Create a sequence generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1  Getting started\n",
    "\n",
    "In this project you will implement a popular Recurrent Neural Network (RNN) architecture to create an English language sequence generator capable of building semi-coherent English sentences from scratch by building them up character-by-character.  This will require a substantial amount amount of parameter tuning on a large training corpus (at least 100,000 characters long).  In particular for this project we will be using a complete version of Sir Arthur Conan Doyle's classic book The Adventures of Sherlock Holmes.\n",
    "\n",
    "How can we train a machine learning model to generate text automatically, character-by-character?  *By showing the model many training examples so it can learn a pattern between input and output.*  With this type of text generation each input is a string of valid characters like this one\n",
    "\n",
    "*dogs are grea*\n",
    "\n",
    "while the corresponding output is the next character in the sentence - which here is 't' (since the complete sentence is 'dogs are great').  We need to show a model many such examples in order for it to make reasonable predictions.\n",
    "\n",
    "**Fun note:** For those interested in how text generation is being used check out some of the following fun resources:\n",
    "\n",
    "- [Generate wacky sentences](http://www.cs.toronto.edu/~ilya/rnn.html) with this academic RNN text generator\n",
    "\n",
    "- Various twitter bots that tweet automatically generated text like[this one](http://tweet-generator-alex.herokuapp.com/).\n",
    "\n",
    "- the [NanoGenMo](https://github.com/NaNoGenMo/2016) annual contest to automatically produce a 50,000+ novel automatically\n",
    "\n",
    "- [Robot Shakespeare](https://github.com/genekogan/RobotShakespeare) a text generator that automatically produces Shakespear-esk sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  Preprocessing a text dataset\n",
    "\n",
    "Our first task is to get a large text corpus for use in training, and on it we perform a several light pre-processing tasks.  The default corpus we will use is the classic book Sherlock Holmes, but you can use a variety of others as well - so long as they are fairly large (around 100,000 characters or more).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our original text has 581864 characters\n"
     ]
    }
   ],
   "source": [
    "# read in the text, transforming everything to lower case\n",
    "text = open('datasets/holmes.txt').read().lower()\n",
    "print('our original text has ' + str(len(text)) + ' characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets examine a bit of the raw text.  Because we are interested in creating sentences of English words automatically by building up each word character-by-character, we only want to train on valid English words.  In other words - we need to remove all of the other characters that are not part of English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeffproject gutenberg's the adventures of sherlock holmes, by arthur conan doyle\\n\\nthis ebook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  you may copy it, give it away or\\nre-use it under the terms of the project gutenberg license included\\nwith this ebook or online at www.gutenberg.net\\n\\n\\ntitle: the adventures of sherlock holmes\\n\\nauthor: arthur conan doyle\\n\\nposting date: april 18, 2011 [ebook #1661]\\nfirst posted: november 29, 2002\\n\\nlanguage: english\\n\\n\\n*** start of this project gutenberg ebook the adventures of sherlock holmes ***\\n\\n\\n\\n\\nproduced by an anonymous project gutenberg volunteer and jose menendez\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nthe adventures of sherlock holmes\\n\\nby\\n\\nsir arthur conan doyle\\n\\n\\n\\n   i. a scandal in bohemia\\n  ii. the red-headed league\\n iii. a case of identity\\n  iv. the boscombe valley mystery\\n   v. the five orange pips\\n  vi. the man with the twisted lip\\n vii. the adventure of the blue carbuncle\\nviii. the adventure of the speckled band\\n  ix. the adventure of the engineer's thumb\\n   x. the adventure of the noble bachelor\\n  xi. the adventure of the beryl coronet\\n xii. the adventure of the copper beeches\\n\\n\\n\\n\\nadventure i. a scandal in bohemia\\n\\ni.\\n\\nto sherlock holmes she is always the woman. i have seldom heard\\nhim mention her under any other name. in his eyes she eclipses\\nand predominates the whole of her sex. it was not that he felt\\nany emotion akin to love for irene adler. all emotions, and that\\none particularly, were abhorrent to his cold, precise but\\nadmirably balanced mind. he was, i take it, the most perfect\\nreasoning and observing machine that the world has seen, but as a\\nlover he would have placed himself in a false position. he never\\nspoke of the softer passions, save with a gibe and a sneer. they\\nwere admirable things for the observer--excellent for drawing the\\nveil from men's motives and actions. but for the trained reasoner\\nto admit such intrusions into his own delicate and finely\\nadjusted temperament was to introduce a dist\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### print out the first 1000 characters of the raw text to get a sense of what we need to throw out\n",
    "text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow - there's a lot of junk here (i.e., weird uncommon character combinations - as this first character chunk contains the title and author page, as well as table of contents)!  To keep things simple, we want to train our RNN on a large chunk of more typical English sentences - we don't want it to start thinking non-english words or strange characters are valid! - so lets clean up the data a bit.\n",
    "\n",
    "First, since the dataset is so large and the first few hundred characters contain a lot of junk, lets cut it out.  Lets also find-and-replace those newline tags with empty spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find and replace '\\n' and '\\r' symbols - replacing them \n",
    "text = text[1302:]\n",
    "text = text.replace('\\n',' ')    # replacing '\\n' with '' simply removes the sequence\n",
    "text = text.replace('\\r',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how the first 1000 characters of our text looks now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"is eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. he never spoke of the softer passions, save with a gibe and a sneer. they were admirable things for the observer--excellent for drawing the veil from men's motives and actions. but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. and yet there was but one woman to him, and that woman was the late irene ad\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### print out the first 1000 characters of the raw text to get a sense of what we need to throw out\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_3'></a>\n",
    "\n",
    "#### TODO: finish cleaning the text\n",
    "\n",
    "Lets make sure we haven't left any other atypical characters (commas, periods, etc., are ok) lurking around in the depths of the text.  You can do this by enumerating all the text's unique characters, examining them, and then replacing any unwanted characters with empty spaces!  Once we find all of the text's unique characters, we can remove all of the atypical ones in the next cell.  Note: don't remove the punctuation marks given in my_answers.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: implement cleaned_text in my_answers.py\n",
    "from my_answers import cleaned_text\n",
    "\n",
    "text = cleaned_text(text)\n",
    "\n",
    "# shorten any extra dead space created above\n",
    "text = text.replace('  ',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your chosen characters removed print out the first few hundred lines again just to double check that everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"is eyes she eclipses and predominates the whole of her sex it was not that he felt any emotion akin to love for irene adler all emotions and that one particularly were abhorrent to his cold precise but admirably balanced mind he was i take it the most perfect reasoning and observing machine that the world has seen but as a lover he would have placed himself in a false position he never spoke of the softer passions save with a gibe and a sneer they were admirable things for the observer--excellent for drawing the veil from men's motives and actions but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results grit in a sensitive instrument or a crack in one of his own high-power lenses would not be more disturbing than a strong emotion in a nature such as his and yet there was but one woman to him and that woman was the late irene adler of dubious and questionable memory  i had seen little of holmes lately my marriage had drifted us away from each other my own complete happiness and the home-centred interests which rise up around the man who first finds himself master of his own establishment were sufficient to absorb all my attention while holmes who loathed every form of society with his whole bohemian soul remained in our lodgings in baker street buried among his old books and alternating from week to week between cocaine and ambition the drowsiness of the drug and the fierce energy of his own keen nature he was still as ever deeply attracted by the study of crime and occupied his immense faculties and extraordinary powers of observation in following out those clues and clearing up those mysteries which had been abandoned as hopeless by the official police from time to time i heard some vague account of his doings of his summons to odessa in the case of the trepoff murder of his clearing up of the singular tragedy of the atkinso\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### print out the first 2000 characters of the raw text to get a sense of what we need to throw out\n",
    "text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have thrown out a good number of non-English characters/character sequences lets print out some statistics about the dataset - including number of total characters and number of unique characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has 565816 total number of characters\n",
      "this corpus has 52 unique characters\n"
     ]
    }
   ],
   "source": [
    "# count the number of unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# print some of the text, as well as statistics\n",
    "print (\"this corpus has \" +  str(len(text)) + \" total number of characters\")\n",
    "print (\"this corpus has \" +  str(len(chars)) + \" unique characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3  Cutting data into input/output pairs\n",
    "\n",
    "Now that we have our text all cleaned up, how can we use it to train a model to generate sentences automatically?  First we need to train a machine learning model - and in order to do that we need a set of input/output pairs for a model to train on.  How can we create a set of input/output pairs from our text to train on?\n",
    "\n",
    "Remember in part 1 of this notebook how we used a sliding window to extract input/output pairs from a time series?  We do the same thing here!  We slide a window of length $T$ along our giant text corpus - everything in the window becomes one input while the character following becomes its corresponding output.  This process of extracting input/output pairs is illustrated in the gif below on a small example text using a window size of T = 5.\n",
    "\n",
    "<img src=\"images/text_windowing_training.gif\" width=400 height=400/>\n",
    "\n",
    "Notice one aspect of the sliding window in this gif that does not mirror the analogous gif for time series shown in part 1 of the notebook - we do not need to slide the window along one character at a time but can move by a fixed step size $M$ greater than 1 (in the gif indeed $M = 1$).  This is done with large input texts (like ours which has over 500,000 characters!) when sliding the window along one character at a time we would create far too many input/output pairs to be able to reasonably compute with.\n",
    "\n",
    "More formally lets denote our text corpus - which is one long string of characters - as follows\n",
    "\n",
    "$$s_{0},s_{1},s_{2},...,s_{P}$$\n",
    "\n",
    "where $P$ is the length of the text (again for our text $P \\approx 500,000!$).  Sliding a window of size T = 5 with a step length of M = 1 (these are the parameters shown in the gif above) over this sequence produces the following list of input/output pairs\n",
    "\n",
    "\n",
    "$$\\begin{array}{c|c}\n",
    "\\text{Input} & \\text{Output}\\\\\n",
    "\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n",
    "\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n",
    "\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n",
    "\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n",
    "\\end{array}$$\n",
    "\n",
    "Notice here that each input is a sequence (or vector) of 5 characters (and in general has length equal to the window size T) while each corresponding output is a single character.  We created around P total number of input/output pairs  (for general step size M we create around ceil(P/M) pairs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_4'></a>\n",
    "\n",
    "Now its time for you to window the input time series as described above! \n",
    "\n",
    "**TODO:** Create a function that runs a sliding window along the input text and creates associated input/output pairs.  A skeleton function has been provided for you.  Note that this function should input a) the text  b) the window size and c) the step size, and return the input/output sequences.  Note: the return items should be *lists* - not numpy arrays.\n",
    "\n",
    "(remember to copy your completed function into the script *my_answers.py* function titled *window_transform_text* before submitting your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: implement window_transform_series in my_answers.py\n",
    "from my_answers import window_transform_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our function complete we can now use it to produce input/output pairs!  We employ the function in the next cell, where the window_size = 50 and step_size = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run your text window-ing function \n",
    "window_size = 100\n",
    "step_size = 5\n",
    "inputs, outputs = window_transform_text(text,window_size,step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print out a few input/output pairs to verify that we have made the right sort of stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = e eclipses and predominates the whole of her sex it was not that he felt any emotion akin to love fo\n",
      "output = r\n",
      "--------------\n",
      "input = t for drawing the veil from men's motives and actions but for the trained reasoner to admit such int\n",
      "output = r\n"
     ]
    }
   ],
   "source": [
    "# print out a few of the input/output pairs to verify that we've made the right kind of stuff to learn from\n",
    "print('input = ' + inputs[2])\n",
    "print('output = ' + outputs[2])\n",
    "print('--------------')\n",
    "print('input = ' + inputs[100])\n",
    "print('output = ' + outputs[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4  Wait, what kind of problem is text generation again?\n",
    "\n",
    "In part 1 of this notebook we used the same pre-processing technique - the sliding window - to produce a set of training input/output pairs to tackle the problem of time series prediction *by treating the problem as one of regression*.  So what sort of problem do we have here now, with text generation?  Well, the time series prediction was a regression problem because the output (one value of the time series) was a continuous value.  Here - for character-by-character text generation - each output is a *single character*.  This isn't a continuous value - but a distinct class - therefore **character-by-character text generation is a classification problem**.  \n",
    "\n",
    "How many classes are there in the data?  Well, the number of classes is equal to the number of unique characters we have to predict!  How many of those were there in our dataset again?  Lets print out the value again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has 52 unique characters\n",
      "and these characters are \n",
      "[' ', '\"', '$', '%', '&', \"'\", '(', ')', '*', '-', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '@', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "# print out the number of unique characters in the dataset\n",
    "chars = sorted(list(set(text)))\n",
    "print (\"this corpus has \" +  str(len(chars)) + \" unique characters\")\n",
    "print ('and these characters are ')\n",
    "print (chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rockin' - so we have a multiclass classification problem on our hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5  One-hot encoding characters\n",
    "\n",
    "The last issue we have to deal with is representing our text data as numerical data so that we can use it as an input to a neural network. One of the conceptually simplest ways of doing this is via a 'one-hot encoding' scheme.  Here's how it works.\n",
    "\n",
    "We transform each character in our inputs/outputs into a vector with length equal to the number of unique characters in our text.  This vector is all zeros except one location where we place a 1 - and this location is unique to each character type.  e.g., we transform 'a', 'b', and 'c' as follows\n",
    "\n",
    "$$a\\longleftarrow\\left[\\begin{array}{c}\n",
    "1\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right]\\,\\,\\,\\,\\,\\,\\,b\\longleftarrow\\left[\\begin{array}{c}\n",
    "0\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right]\\,\\,\\,\\,\\,c\\longleftarrow\\left[\\begin{array}{c}\n",
    "0\\\\\n",
    "0\\\\\n",
    "1\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0 \n",
    "\\end{array}\\right]\\cdots$$\n",
    "\n",
    "where each vector has 32 entries (or in general: number of entries = number of unique characters in text)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first practical step towards doing this one-hot encoding is to form a dictionary mapping each unique character to a unique integer, and one dictionary to do the reverse mapping.  We can then use these dictionaries to quickly make our one-hot encodings, as well as re-translate (from integers to characters) the results of our trained RNN classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary is a function mapping each unique character to a unique integer\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "\n",
    "# this dictionary is a function mapping each unique integer back to a unique character\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can transform our input/output pairs - consisting of characters - to equivalent input/output pairs made up of one-hot encoded vectors.  In the next cell we provide a function for doing just this: it takes in the raw character input/outputs and returns their numerical versions.  In particular the numerical input is given as $\\bf{X}$, and numerical output is given as the $\\bf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform character-based input/output into equivalent numerical versions\n",
    "def encode_io_pairs(text,window_size,step_size):\n",
    "    # number of unique chars\n",
    "    chars = sorted(list(set(text)))\n",
    "    num_chars = len(chars)\n",
    "    \n",
    "    # cut up text into character input/output pairs\n",
    "    inputs, outputs = window_transform_text(text,window_size,step_size)\n",
    "    \n",
    "    # create empty vessels for one-hot encoded input/output\n",
    "    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.bool)\n",
    "    y = np.zeros((len(inputs), num_chars), dtype=np.bool)\n",
    "    \n",
    "    # loop over inputs/outputs and transform and store in X/y\n",
    "    for i, sentence in enumerate(inputs):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, chars_to_indices[char]] = 1\n",
    "        y[i, chars_to_indices[outputs[i]]] = 1\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the one-hot encoding function by activating the cell below and transform our input/output pairs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your function\n",
    "window_size = 100\n",
    "step_size = 5\n",
    "X,y = encode_io_pairs(text,window_size,step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_5'></a>\n",
    "\n",
    "## 2.6 Setting up our RNN\n",
    "\n",
    "With our dataset loaded and the input/output pairs extracted / transformed we can now begin setting up our RNN for training.  Again we will use Keras to quickly build a single hidden layer RNN - where our hidden layer consists of LSTM modules.\n",
    "\n",
    "Time to get to work: build a 3 layer RNN model of the following specification\n",
    "\n",
    "- layer 1 should be an LSTM module with 200 hidden units --> note this should have input_shape = (window_size,len(chars)) where len(chars) = number of unique characters in your cleaned text\n",
    "- layer 2 should be a linear module, fully connected, with len(chars) hidden units --> where len(chars) = number of unique characters in your cleaned text\n",
    "- layer 3 should be a softmax activation ( since we are solving a *multiclass classification*)\n",
    "- Use the **categorical_crossentropy** loss \n",
    "\n",
    "This network can be constructed using just a few lines - as with the RNN network you made in part 1 of this notebook.  See e.g., the [general Keras documentation](https://keras.io/getting-started/sequential-model-guide/) and the [LSTM documentation in particular](https://keras.io/layers/recurrent/) for examples of how to quickly use Keras to build neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### necessary functions from the keras library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras\n",
    "import random\n",
    "\n",
    "# TODO implement build_part2_RNN in my_answers.py\n",
    "from my_answers import build_part2_RNN\n",
    "\n",
    "model = build_part2_RNN(window_size, len(chars))\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7  Training our RNN model for text generation\n",
    "\n",
    "With our RNN setup we can now train it!  Lets begin by trying it out on a small subset of the larger version.  In the next cell we take the first 10,000 input/output pairs from our training database to learn on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a small subset of our input/output pairs\n",
    "Xsmall = X[:10000,:,:]\n",
    "ysmall = y[:10000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets fit our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 3.1207\n",
      "Epoch 2/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.8845\n",
      "Epoch 3/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 2.8574\n",
      "Epoch 4/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 2.8301\n",
      "Epoch 5/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 2.7842\n",
      "Epoch 6/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 2.7303\n",
      "Epoch 7/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 2.6716\n",
      "Epoch 8/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 2.6121\n",
      "Epoch 9/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 2.5613\n",
      "Epoch 10/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.5171\n",
      "Epoch 11/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 2.4742\n",
      "Epoch 12/40\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 2.4399\n",
      "Epoch 13/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.4030\n",
      "Epoch 14/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 2.3812\n",
      "Epoch 15/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 2.3474\n",
      "Epoch 16/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3258\n",
      "Epoch 17/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3030\n",
      "Epoch 18/40\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 2.2841\n",
      "Epoch 19/40\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 2.2641\n",
      "Epoch 20/40\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 2.2425\n",
      "Epoch 21/40\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 2.2285\n",
      "Epoch 22/40\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 2.2066\n",
      "Epoch 23/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.1911\n",
      "Epoch 24/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.1729\n",
      "Epoch 25/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.1569\n",
      "Epoch 26/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.1451\n",
      "Epoch 27/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.1217\n",
      "Epoch 28/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.1095\n",
      "Epoch 29/40\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 2.0961\n",
      "Epoch 30/40\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 2.0813\n",
      "Epoch 31/40\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 2.0654\n",
      "Epoch 32/40\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 2.0522\n",
      "Epoch 33/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.0378\n",
      "Epoch 34/40\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 2.0235\n",
      "Epoch 35/40\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 2.0121\n",
      "Epoch 36/40\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 1.9975\n",
      "Epoch 37/40\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 1.9793\n",
      "Epoch 38/40\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 1.9691\n",
      "Epoch 39/40\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 1.9501\n",
      "Epoch 40/40\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 1.9411\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(Xsmall, ysmall, batch_size=500, epochs=40,verbose = 1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_RNN_small_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we make a given number of predictions (characters) based on this fitted model?   \n",
    "\n",
    "First we predict the next character after following any chunk of characters in the text of length equal to our chosen window size.  Then we remove the first character in our input sequence and tack our prediction onto the end.  This gives us a slightly changed sequence of inputs that still has length equal to the size of our window.  We then feed in this updated input sequence into the model to predict the another character.  Together then we have two predicted characters following our original input sequence.  Repeating this process N times gives us N predicted characters.\n",
    "\n",
    "In the next Python cell we provide you with a completed function that does just this - it makes predictions when given a) a trained RNN model, b) a subset of (window_size) characters from the text, and c) a number of characters to predict (to follow our input subset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that uses trained model to predict a desired number of future characters\n",
    "def predict_next_chars(model,input_chars,num_to_predict):     \n",
    "    # create output\n",
    "    predicted_chars = ''\n",
    "    for i in range(num_to_predict):\n",
    "        # convert this round's predicted characters to numerical input    \n",
    "        x_test = np.zeros((1, window_size, len(chars)))\n",
    "        for t, char in enumerate(input_chars):\n",
    "            x_test[0, t, chars_to_indices[char]] = 1.\n",
    "\n",
    "        # make this round's prediction\n",
    "        test_predict = model.predict(x_test,verbose = 0)[0]\n",
    "\n",
    "        # translate numerical prediction back to characters\n",
    "        r = np.argmax(test_predict)                           # predict class of each test input\n",
    "        d = indices_to_chars[r] \n",
    "\n",
    "        # update predicted_chars and input\n",
    "        predicted_chars+=d\n",
    "        input_chars+=d\n",
    "        input_chars = input_chars[1:]\n",
    "    return predicted_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_6'></a>\n",
    "\n",
    "With your trained model try a few subsets of the complete text as input - note the length of each must be exactly equal to the window size.  For each subset use the function above to predict the next 100 characters that follow each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "is eyes she eclipses and predominates the whole of her sex it was not that he felt any emotion akin \"\n",
      "\n",
      "predicted chars = \n",
      "the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "s  a man entered who could hardly have been less than six feet six inches in height with the chest a\"\n",
      "\n",
      "predicted chars = \n",
      "nd the sher whin the sout the sout the sout the sout the sout the sout the sout the sout the sout th\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ockets he stretched out his legs in front of the fire and laughed heartily for some minutes  \"well r\"\n",
      "\n",
      "predicted chars = \n",
      "eand be the pont in the sout the sout the sout the sout the sout the sout the sout the sout the sout\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "that holmes changed his costume his expression his manner his very soul seemed to vary with every fr\"\n",
      "\n",
      "predicted chars = \n",
      "ome in the she sound and and and and and and and and and and and and and and and and and and and and\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ut she could not love him \" \"i am in hopes that she does \" \"and why in hopes \" \"because it would spa\"\n",
      "\n",
      "predicted chars = \n",
      "nd and and and and and and and and and and and and and and and and and and and and and and and and a\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " larger than your left you have worked with it and the muscles are more developed \" \"well the snuff \"\n",
      "\n",
      "predicted chars = \n",
      "the pont the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "y wigs and once by paint i could tell you tales of cobbler's wax which would disgust you with human \"\n",
      "\n",
      "predicted chars = \n",
      "the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "monplace face is the most difficult to identify but i must be prompt over this matter \" \"what are yo\"\n",
      "\n",
      "predicted chars = \n",
      "u the pont in the sout the sout the sout the sout the sout the sout the sout the sout the sout the s\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " in cornwall the next i've been on his track for years and have never set eyes on him yet \" \"i hope \"\n",
      "\n",
      "predicted chars = \n",
      "the the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the so\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "him and what was it to them who were playing for thousands they put in the advertisement one rogue h\"\n",
      "\n",
      "predicted chars = \n",
      "ad the sher and and and and and and and and and and and and and and and and and and and and and and \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " the machine and i would give it all to know what has become of mr hosmer angel \" \"why did you come \"\n",
      "\n",
      "predicted chars = \n",
      "the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ot write oh it drives me half-mad to think of it and i can't sleep a wink at night \" she pulled a li\"\n",
      "\n",
      "predicted chars = \n",
      "ng the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sou\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " slight bow sidled down into the nearest chair  \"good-evening mr james windibank \" said holmes \"i th\"\n",
      "\n",
      "predicted chars = \n",
      "e come the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "danger also for whoso snatches a delusion from a woman ' there is as much sense in hafiz as in horac\"\n",
      "\n",
      "predicted chars = \n",
      "e and the pand the she sound and and and and and and and and and and and and and and and and and and\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "of the coroner's jury \" \"it was a confession \" i ejaculated  \"no for it was followed by a protestati\"\n",
      "\n",
      "predicted chars = \n",
      " the sowe the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "e read the evidence you have formed some conclusion do you not see some loophole some flaw do you no\"\n",
      "\n",
      "predicted chars = \n",
      "un the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sou\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ve grasped one fact which you seem to find it difficult to get hold of \" replied lestrade with some \"\n",
      "\n",
      "predicted chars = \n",
      "tout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the s\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ty of the criminal \" \"but how did you gain them \" \"you know my method it is founded upon the observa\"\n",
      "\n",
      "predicted chars = \n",
      "n the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "and submitted to the defending counsel old turner lived for seven months after our interview but he \"\n",
      "\n",
      "predicted chars = \n",
      "was dout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ld rusty key which must have belonged to the attic in one hand and a small brass box like a cashbox \"\n",
      "\n",
      "predicted chars = \n",
      "and the sher whin the sout the sout the sout the sout the sout the sout the sout the sout the sout t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ed the papers i observed that the small unburned margins which lay amid the ashes were of this parti\"\n",
      "\n",
      "predicted chars = \n",
      "ng the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sou\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "on seeds or orange pips in others on receiving this the victim might either openly abjure his former\"\n",
      "\n",
      "predicted chars = \n",
      " and and and and and and and and and and and and and and and and and and and and and and and and and\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "lady clad in some dark-coloured stuff with a black veil entered the room  \"you will excuse my callin\"\n",
      "\n",
      "predicted chars = \n",
      "g and and and and and and and and and and and and and and and and and and and and and and and and an\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "t need you here's half a crown look out for me to-morrow about eleven give her her head so long then\"\n",
      "\n",
      "predicted chars = \n",
      " the sher dound and and and and and and and and and and and and and and and and and and and and and \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "s her presence could be of no help to them in their investigations inspector barton who had charge o\"\n",
      "\n",
      "predicted chars = \n",
      "f the pand the sher whan the sout the sout the sout the sout the sout the sout the sout the sout the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " a sympathy between us that i should know if evil came upon him on the very day that i saw him last \"\n",
      "\n",
      "predicted chars = \n",
      "and and and and and and and and and and and and and and and and and and and and and and and and and \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ve them ashamed of their father my god what an exposure what can i do \" sherlock holmes sat down bes\"\n",
      "\n",
      "predicted chars = \n",
      " and the sher whin the sout the sout the sout the sout the sout the sout the sout the sout the sout \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ranger from his assailants but the man shocked at having broken the window and seeing an official-lo\"\n",
      "\n",
      "predicted chars = \n",
      "f the pared and the sout the sout the sout the sout the sout the sout the sout the sout the sout the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ad remained with horner some little time but had finally been called away on returning he found that\"\n",
      "\n",
      "predicted chars = \n",
      " the sher dound and and and and and and and and and and and and and and and and and and and and and \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "on't know him well here's your good health landlord and prosperity to your house good-night \" \"now f\"\n",
      "\n",
      "predicted chars = \n",
      "rot the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the so\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ds and all the proofs which i could possibly need so there is little which you need tell me still th\"\n",
      "\n",
      "predicted chars = \n",
      "e sher whan the sout the sout the sout the sout the sout the sout the sout the sout the sout the sou\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "\" i had no keener pleasure than in following holmes in his professional investigations and in admiri\"\n",
      "\n",
      "predicted chars = \n",
      "se and and and and and and and and and and and and and and and and and and and and and and and and a\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "ne where she sat for some time chatting about her approaching wedding at eleven o'clock she rose to \"\n",
      "\n",
      "predicted chars = \n",
      "the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "denly dashed open and that a huge man had framed himself in the aperture his costume was a peculiar \"\n",
      "\n",
      "predicted chars = \n",
      "and and and and and and and and and and and and and and and and and and and and and and and and and \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "last pointing to a thick bell-rope which hung down beside the bed the tassel actually lying upon the\"\n",
      "\n",
      "predicted chars = \n",
      " sher whal dound and and and and and and and and and and and and and and and and and and and and and\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ke a vice upon my wrist in his agitation then he broke into a low laugh and put his lips to my ear  \"\n",
      "\n",
      "predicted chars = \n",
      "has doun the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "has i believe been told more than once in the newspapers but like all such narratives its effect is \"\n",
      "\n",
      "predicted chars = \n",
      "and the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the so\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "\"i bowed feeling as flattered as any young man would at such an address 'may i ask who it was who ga\"\n",
      "\n",
      "predicted chars = \n",
      "t the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " shone upon her dark dress i knew that it was a rich material she spoke a few words in a foreign ton\"\n",
      "\n",
      "predicted chars = \n",
      " the sist and the sout the sout the sout the sout the sout the sout the sout the sout the sout the s\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ard for an instant i could hardly believe that here was indeed a door which led away from death the \"\n",
      "\n",
      "predicted chars = \n",
      "sher dound and and and and and and and and and and and and and and and and and and and and and and a\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ill and there was a great widespread whitewashed building in front of us spouting fire at every chin\"\n",
      "\n",
      "predicted chars = \n",
      "g the sher dound and and and and and and and and and and and and and and and and and and and and and\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " \" asked holmes yawning  \"oh yes plenty then there is another note in the morning post to say that t\"\n",
      "\n",
      "predicted chars = \n",
      "he sher whal d and and and and and and and and and and and and and and and and and and and and and a\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "he pew handed it up to her again and it did not appear to be the worse for the fall yet when i spoke\"\n",
      "\n",
      "predicted chars = \n",
      " to the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the so\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " important all the same as to the note it is important also or at least the initials are so i congra\"\n",
      "\n",
      "predicted chars = \n",
      "nd was and and and and and and and and and and and and and and and and and and and and and and and a\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "y somewhere where no one could find them it is likely that we should have gone on to paris to-morrow\"\n",
      "\n",
      "predicted chars = \n",
      "h what he sound and and and and and and and and and and and and and and and and and and and and and \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "l with another effort he braced himself to tell his story  \"i feel that time is of value \" said he \"\"\n",
      "\n",
      "predicted chars = \n",
      " \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ittle of what he said he followed me to my room however that night with a very grave face  \"'look he\"\n",
      "\n",
      "predicted chars = \n",
      " was dout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " whole way out to the southern suburb but sat with his chin upon his breast and his hat drawn over h\"\n",
      "\n",
      "predicted chars = \n",
      "as dound and and and and and and and and and and and and and and and and and and and and and and and\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "\"i only looked in as i passed \" said he \"i am going right on \" \"where to \" \"oh to the other side of \"\n",
      "\n",
      "predicted chars = \n",
      "the pand the she sound and and and and and and and and and and and and and and and and and and and a\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "heart of whom you had already spoken to me and inquiry showed it was so i passed round the garden wi\"\n",
      "\n",
      "predicted chars = \n",
      "th a dould and and and and and and and and and and and and and and and and and and and and and and a\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "if i do not inconvenience you yours faithfully                         \"violet hunter \" \"do you know\"\n",
      "\n",
      "predicted chars = \n",
      " the sould and and and and and and and and and and and and and and and and and and and and and and a\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "t however that before taking the final step i should like to submit the whole matter to your conside\"\n",
      "\n",
      "predicted chars = \n",
      " and the sist and the sout the sout the sout the sout the sout the sout the sout the sout the sout t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " easy to see that she was passionately devoted both to her husband and to her little son her light g\"\n",
      "\n",
      "predicted chars = \n",
      "ot the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sou\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "d and a look on his face which made him a very different person to the round jovial man to whom i wa\"\n",
      "\n",
      "predicted chars = \n",
      "s dout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ed holmes  a loud thudding noise came from somewhere downstairs \"that is mrs toller in the cellar \" \"\n",
      "\n",
      "predicted chars = \n",
      "\"and and the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " entity to whom you paid the fee as set forth in paragraph 1 e 8  1 b  \"project gutenberg\" is a regi\"\n",
      "\n",
      "predicted chars = \n",
      "t the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "r limitation of certain types of damages if any disclaimer or limitation set forth in this agreement\"\n",
      "\n",
      "predicted chars = \n",
      " and and and and and and and and and and and and and and and and and and and and and and and and and\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: choose an input sequence and use the prediction function in the previous Python cell to predict 100 characters following it\n",
    "# get an appropriately sized chunk of characters from the text\n",
    "start_inds = range(0, len(text), 10000)\n",
    "\n",
    "# load in weights\n",
    "model.load_weights('model_weights/best_RNN_small_textdata_weights.hdf5')\n",
    "for s in start_inds:\n",
    "    start_index = s\n",
    "    input_chars = text[start_index: start_index + window_size]\n",
    "\n",
    "    # use the prediction function\n",
    "    predict_input = predict_next_chars(model,input_chars,num_to_predict = 100)\n",
    "\n",
    "    # print out input characters\n",
    "    print('------------------')\n",
    "    input_line = 'input chars = ' + '\\n' +  input_chars + '\"' + '\\n'\n",
    "    print(input_line)\n",
    "\n",
    "    # print out predicted characters\n",
    "    line = 'predicted chars = ' + '\\n' +  predict_input + '\"' + '\\n'\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks ok, but not great.  Now lets try the same experiment with a larger chunk of the data - with the first 100,000 input/output pairs.  \n",
    "\n",
    "Tuning RNNs for a typical character dataset like the one we will use here is a computationally intensive endeavour and thus timely on a typical CPU.  Using a reasonably sized cloud-based GPU can speed up training by a factor of 10.  Also because of the long training time it is highly recommended that you carefully write the output of each step of your process to file.  This is so that all of your results are saved even if you close the web browser you're working out of, as the processes will continue processing in the background but variables/output in the notebook system will not update when you open it again.\n",
    "\n",
    "In the next cell we show you how to create a text file in Python and record data to it.  This sort of setup can be used to record your final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is only a test \\nthe value of x is 2\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### A simple way to write output to file\n",
    "f = open('my_test_output.txt', 'w')              # create an output file to write too\n",
    "f.write('this is only a test ' + '\\n')           # print some output text\n",
    "x = 2\n",
    "f.write('the value of x is ' + str(x) + '\\n')    # record a variable value\n",
    "f.close()     \n",
    "\n",
    "# print out the contents of my_test_output.txt\n",
    "f = open('my_test_output.txt', 'r')              # create an output file to write too\n",
    "f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this recording devices we can now more safely perform experiments on larger portions of the text.  In the next cell we will use the first 100,000 input/output pairs to train our RNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we fit our model to the dataset, then generate text using the trained model in precisely the same generation method applied before on the small dataset.\n",
    "\n",
    "**Note:** your generated words should be - by and large - more realistic than with the small dataset, but you won't be able to generate perfect English sentences even with this amount of data.  A rule of thumb: your model is working well if you generate sentences that largely contain real English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100000/100000 [==============================] - 174s 2ms/step - loss: 2.0453\n",
      "Epoch 2/30\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 1.9661\n",
      "Epoch 3/30\n",
      "100000/100000 [==============================] - 181s 2ms/step - loss: 1.9072\n",
      "Epoch 4/30\n",
      "100000/100000 [==============================] - 193s 2ms/step - loss: 1.8571\n",
      "Epoch 5/30\n",
      "100000/100000 [==============================] - 193s 2ms/step - loss: 1.8129\n",
      "Epoch 6/30\n",
      "100000/100000 [==============================] - 199s 2ms/step - loss: 1.7734\n",
      "Epoch 7/30\n",
      "100000/100000 [==============================] - 175s 2ms/step - loss: 1.7371\n",
      "Epoch 8/30\n",
      "100000/100000 [==============================] - 165s 2ms/step - loss: 1.7035\n",
      "Epoch 9/30\n",
      "100000/100000 [==============================] - 186s 2ms/step - loss: 1.6728\n",
      "Epoch 10/30\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 1.6439\n",
      "Epoch 11/30\n",
      "100000/100000 [==============================] - 174s 2ms/step - loss: 1.6161\n",
      "Epoch 12/30\n",
      "100000/100000 [==============================] - 175s 2ms/step - loss: 1.5886\n",
      "Epoch 13/30\n",
      "100000/100000 [==============================] - 174s 2ms/step - loss: 1.5644\n",
      "Epoch 14/30\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 1.5392\n",
      "Epoch 15/30\n",
      "100000/100000 [==============================] - 166s 2ms/step - loss: 1.5150\n",
      "Epoch 16/30\n",
      "100000/100000 [==============================] - 158s 2ms/step - loss: 1.4918\n",
      "Epoch 17/30\n",
      "100000/100000 [==============================] - 165s 2ms/step - loss: 1.4681\n",
      "Epoch 18/30\n",
      "100000/100000 [==============================] - 164s 2ms/step - loss: 1.4449\n",
      "Epoch 19/30\n",
      "100000/100000 [==============================] - 178s 2ms/step - loss: 1.4228\n",
      "Epoch 20/30\n",
      "100000/100000 [==============================] - 172s 2ms/step - loss: 1.4007\n",
      "Epoch 21/30\n",
      "100000/100000 [==============================] - 161s 2ms/step - loss: 1.3776\n",
      "Epoch 22/30\n",
      "100000/100000 [==============================] - 164s 2ms/step - loss: 1.3558\n",
      "Epoch 23/30\n",
      "100000/100000 [==============================] - 164s 2ms/step - loss: 1.3344\n",
      "Epoch 24/30\n",
      "100000/100000 [==============================] - 176s 2ms/step - loss: 1.3129\n",
      "Epoch 25/30\n",
      "100000/100000 [==============================] - 200s 2ms/step - loss: 1.2913\n",
      "Epoch 26/30\n",
      "100000/100000 [==============================] - 181s 2ms/step - loss: 1.2696\n",
      "Epoch 27/30\n",
      "100000/100000 [==============================] - 194s 2ms/step - loss: 1.2487\n",
      "Epoch 28/30\n",
      "100000/100000 [==============================] - 164s 2ms/step - loss: 1.2262\n",
      "Epoch 29/30\n",
      "100000/100000 [==============================] - 177s 2ms/step - loss: 1.2068\n",
      "Epoch 30/30\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 1.1838\n"
     ]
    }
   ],
   "source": [
    "# a small subset of our input/output pairs\n",
    "Xlarge = X[:100000,:,:]\n",
    "ylarge = y[:100000,:]\n",
    "\n",
    "# TODO: fit to our larger dataset\n",
    "model.fit(Xlarge, ylarge, batch_size=500, epochs=30, verbose=1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_RNN_large_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "\n",
      "input chars = \n",
      "is eyes she eclipses and predominates the whole of her sex it was not that he felt any emotion akin \"\n",
      "\n",
      "predicted chars = \n",
      "the enceed upon at his eye when the care was no longured and the fire of the bed and she cooken alon\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "s  a man entered who could hardly have been less than six feet six inches in height with the chest a\"\n",
      "\n",
      "predicted chars = \n",
      "nd the street which can he was a smoll was in one of the self---moloor which i had den ampleary comp\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ockets he stretched out his legs in front of the fire and laughed heartily for some minutes  \"well r\"\n",
      "\n",
      "predicted chars = \n",
      "e absert do no \" \"there is a remar commany \" \"yes \" \"and you will for you street to you surper that \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "that holmes changed his costume his expression his manner his very soul seemed to vary with every fr\"\n",
      "\n",
      "predicted chars = \n",
      "om the rest he stoke him as i am alown the distartere of the secent which i had to meath the latter \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ut she could not love him \" \"i am in hopes that she does \" \"and why in hopes \" \"because it would spa\"\n",
      "\n",
      "predicted chars = \n",
      "rd it is it is a mird the fire of the morning \" \"i as arready \"but it she lay and the fires \" \"i and\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " larger than your left you have worked with it and the muscles are more developed \" \"well the snuff \"\n",
      "\n",
      "predicted chars = \n",
      "the morth \" \"i see me to see my door and i have no doubt you that is is a rindly and i am a realy \" \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "y wigs and once by paint i could tell you tales of cobbler's wax which would disgust you with human \"\n",
      "\n",
      "predicted chars = \n",
      "the street \" \"i as a remarked my end it was the bed and the street \" \"i shall not into the side of t\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "monplace face is the most difficult to identify but i must be prompt over this matter \" \"what are yo\"\n",
      "\n",
      "predicted chars = \n",
      "u give me to see she come of the morning \" \"i am arread \" \"you was and you some without of the side \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " in cornwall the next i've been on his track for years and have never set eyes on him yet \" \"i hope \"\n",
      "\n",
      "predicted chars = \n",
      "to you that it is well the trough the man in she may have been seen the stanger of the secent which \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "him and what was it to them who were playing for thousands they put in the advertisement one rogue h\"\n",
      "\n",
      "predicted chars = \n",
      "e had been do starding up i should be a poor court of the morning and the excect of the window here \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " the machine and i would give it all to know what has become of mr hosmer angel \" \"why did you come \"\n",
      "\n",
      "predicted chars = \n",
      "it is it is a mird the fire of the matter \" \"it is a prich to me to you surpers as the litter of the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ot write oh it drives me half-mad to think of it and i can't sleep a wink at night \" she pulled a li\"\n",
      "\n",
      "predicted chars = \n",
      "ttle in the lid for her leated where i can of do be the most came i was see it is well the come i wa\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " slight bow sidled down into the nearest chair  \"good-evening mr james windibank \" said holmes \"i th\"\n",
      "\n",
      "predicted chars = \n",
      "ink that i had the remeres \" \"out the finest the street \" \"i as arready \"there is a sprack and the s\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "danger also for whoso snatches a delusion from a woman ' there is as much sense in hafiz as in horac\"\n",
      "\n",
      "predicted chars = \n",
      "e you \" \"and i have to deary my friend \" \"it was a rimbly that i have been to the man in she was in \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "of the coroner's jury \" \"it was a confession \" i ejaculated  \"no for it was followed by a protestati\"\n",
      "\n",
      "predicted chars = \n",
      "on of the seather \" \"then i have to meany it would be no sen out of the self--the then \" \"and you di\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "e read the evidence you have formed some conclusion do you not see some loophole some flaw do you no\"\n",
      "\n",
      "predicted chars = \n",
      "w that you have not into the without of the morning which i had the pase fer the street \" \"i do not \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ve grasped one fact which you seem to find it difficult to get hold of \" replied lestrade with some \"\n",
      "\n",
      "predicted chars = \n",
      "new the little of the secent which i have to me to me the come i was the bed a monet to me that i ha\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ty of the criminal \" \"but how did you gain them \" \"you know my method it is founded upon the observa\"\n",
      "\n",
      "predicted chars = \n",
      "tion of the case we was at the matter and with the see which he is absome to and the street of the c\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "and submitted to the defending counsel old turner lived for seven months after our interview but he \"\n",
      "\n",
      "predicted chars = \n",
      "is to be an and the matter and without hear but the senter of the secent which i have been seen to c\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ld rusty key which must have belonged to the attic in one hand and a small brass box like a cashbox \"\n",
      "\n",
      "predicted chars = \n",
      "with a should spore he had been do wo door have been so and you are a mondor's from the matter \" \"it\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ed the papers i observed that the small unburned margins which lay amid the ashes were of this parti\"\n",
      "\n",
      "predicted chars = \n",
      "one which i have been seen to compontly and in the distarter \" \"it is all this letter \" \"it is all t\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "on seeds or orange pips in others on receiving this the victim might either openly abjure his former\"\n",
      "\n",
      "predicted chars = \n",
      " and the firet \" \"in you dread \" \"and you did you all the poot may \" \"no no she but of me i should n\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "lady clad in some dark-coloured stuff with a black veil entered the room  \"you will excuse my callin\"\n",
      "\n",
      "predicted chars = \n",
      "g of me with a strock and sell which i have to deary my four the senting \" \"i as a remarkace and the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "t need you here's half a crown look out for me to-morrow about eleven give her her head so long then\"\n",
      "\n",
      "predicted chars = \n",
      " i was a commoning a very good and that it was glome i was seen the door which i had the day and i d\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "s her presence could be of no help to them in their investigations inspector barton who had charge o\"\n",
      "\n",
      "predicted chars = \n",
      "f the matter and without her but he houses and the fire of the bed the door which he was at a man co\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " a sympathy between us that i should know if evil came upon him on the very day that i saw him last \"\n",
      "\n",
      "predicted chars = \n",
      "her been so was it was not in the morning and the corter of the window here who would at the lid the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ve them ashamed of their father my god what an exposure what can i do \" sherlock holmes sat down bes\"\n",
      "\n",
      "predicted chars = \n",
      "ide the sight of the corour ther we was the bear to me when you have been a remoned the street \" \"i \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ranger from his assailants but the man shocked at having broken the window and seeing an official-lo\"\n",
      "\n",
      "predicted chars = \n",
      "ok and the corour ther we was the come i was the fire of the case of the man in she was i was seen t\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ad remained with horner some little time but had finally been called away on returning he found that\"\n",
      "\n",
      "predicted chars = \n",
      " he had been the was a said for the restracte for the pressen whore the case i was to me the there w\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "on't know him well here's your good health landlord and prosperity to your house good-night \" \"now f\"\n",
      "\n",
      "predicted chars = \n",
      "or you she was it is i was a rimbly that i have been there is that i have to me to do the matter of \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ds and all the proofs which i could possibly need so there is little which you need tell me still th\"\n",
      "\n",
      "predicted chars = \n",
      "at i have do not there is a remains \" \"i am all the proves \" \"in the matter \" \"it is a propiced some\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "\" i had no keener pleasure than in following holmes in his professional investigations and in admiri\"\n",
      "\n",
      "predicted chars = \n",
      "ng a man of the matter and the street of the stones which i have been a little to me the trought of \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ne where she sat for some time chatting about her approaching wedding at eleven o'clock she rose to \"\n",
      "\n",
      "predicted chars = \n",
      "the matter of the secent which i have been seen to compontion of his cast a deppace and the fire of \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "denly dashed open and that a huge man had framed himself in the aperture his costume was a peculiar \"\n",
      "\n",
      "predicted chars = \n",
      "of my companion in his case of the matter and without here as i am to the matter of the self---mole \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "last pointing to a thick bell-rope which hung down beside the bed the tassel actually lying upon the\"\n",
      "\n",
      "predicted chars = \n",
      " seement who was as see it is all this interest the sunders whore he was a smoll and we was the fame\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ke a vice upon my wrist in his agitation then he broke into a low laugh and put his lips to my ear  \"\n",
      "\n",
      "predicted chars = \n",
      "\"what is may fet in the street \" \"i should not me to stony state my wits a said a startion \" \"i am a\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "has i believe been told more than once in the newspapers but like all such narratives its effect is \"\n",
      "\n",
      "predicted chars = \n",
      "and the distarter the secter of the street \" \"i should not into the some \" \"i doon that is a rimple \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "\"i bowed feeling as flattered as any young man would at such an address 'may i ask who it was who ga\"\n",
      "\n",
      "predicted chars = \n",
      "ve the same is well we shall not be a salfer and the fire of the care was she was as so me to the ma\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " shone upon her dark dress i knew that it was a rich material she spoke a few words in a foreign ton\"\n",
      "\n",
      "predicted chars = \n",
      "e as a little prop and the firet \" \"it is a sittle me to see you to the matter \" \"it is a propiculy \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ard for an instant i could hardly believe that here was indeed a door which led away from death the \"\n",
      "\n",
      "predicted chars = \n",
      "man in she smore had not here and the count of the man in she smore had not her every with the coust\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ill and there was a great widespread whitewashed building in front of us spouting fire at every chin\"\n",
      "\n",
      "predicted chars = \n",
      "g and the sines which was have have a see of the window  \"i should be a salfer that it was the bed a\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " \" asked holmes yawning  \"oh yes plenty then there is another note in the morning post to say that t\"\n",
      "\n",
      "predicted chars = \n",
      "he drees was not ther we was the bear to me when i can he may for the present \" \"it is a sittle mest\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "he pew handed it up to her again and it did not appear to be the worse for the fall yet when i spoke\"\n",
      "\n",
      "predicted chars = \n",
      " to be the trough the man in she matter of the secent which i have been seen to company that i shoul\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " important all the same as to the note it is important also or at least the initials are so i congra\"\n",
      "\n",
      "predicted chars = \n",
      "tiont to you she was it is a prop cousts of the most came i was seemed to me the bed at the light of\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "y somewhere where no one could find them it is likely that we should have gone on to paris to-morrow\"\n",
      "\n",
      "predicted chars = \n",
      " the trought of the sed the gaid of a morather was and the coneress and he was a side of the window \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "l with another effort he braced himself to tell his story  \"i feel that time is of value \" said he \"\"\n",
      "\n",
      "predicted chars = \n",
      "it is not i can \" \"that is well the led a very son in one of the morning \" \"i am arread \" \"you was a\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ittle of what he said he followed me to my room however that night with a very grave face  \"'look he\"\n",
      "\n",
      "predicted chars = \n",
      "ar that you will for have no doubt you that i have been an once it is that i was and you give me to \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " whole way out to the southern suburb but sat with his chin upon his breast and his hat drawn over h\"\n",
      "\n",
      "predicted chars = \n",
      "is by the case when he was a compleyin for in the matter and with the conered was so net in the matt\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "\"i only looked in as i passed \" said he \"i am going right on \" \"where to \" \"oh to the other side of \"\n",
      "\n",
      "predicted chars = \n",
      "the morning \" \"i am arread \" \"you was and you think that i have been an allowe to you so i found the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "heart of whom you had already spoken to me and inquiry showed it was so i passed round the garden wi\"\n",
      "\n",
      "predicted chars = \n",
      "th the conered was so near the from the two street had not deen sure that the drees which i have bee\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "if i do not inconvenience you yours faithfully                         \"violet hunter \" \"do you know\"\n",
      "\n",
      "predicted chars = \n",
      " you have no doubt you that is it is very murning of the most company \" \"you all the litter of the s\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "t however that before taking the final step i should like to submit the whole matter to your conside\"\n",
      "\n",
      "predicted chars = \n",
      "rally and it was the fame to a man of the morning of a moranger and the ore of the self---mole of he\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " easy to see that she was passionately devoted both to her husband and to her little son her light g\"\n",
      "\n",
      "predicted chars = \n",
      "ave and as in the door which he is absalfer and there we cassed the come of the matter and with the \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "d and a look on his face which made him a very different person to the round jovial man to whom i wa\"\n",
      "\n",
      "predicted chars = \n",
      "s the bed a beggee of the most came the dier when he was a compley and i do not that it is well the \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ed holmes  a loud thudding noise came from somewhere downstairs \"that is mrs toller in the cellar \" \"\n",
      "\n",
      "predicted chars = \n",
      "\"and the lid then \" \"and you dear compleer wood--\" \"then i should not me to stenting in the could \" \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " entity to whom you paid the fee as set forth in paragraph 1 e 8  1 b  \"project gutenberg\" is a regi\"\n",
      "\n",
      "predicted chars = \n",
      "vely \" \"and you drear \"that i should not be a saguented some and it is it is not conturt you then th\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "r limitation of certain types of damages if any disclaimer or limitation set forth in this agreement\"\n",
      "\n",
      "predicted chars = \n",
      " who had been surded his sone of the matter and without hear but the senter which he is absome to al\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: choose an input sequence and use the prediction function in the previous Python cell to predict 100 characters following it\n",
    "# get an appropriately sized chunk of characters from the text\n",
    "start_inds = list(range(0, len(text), 10000))\n",
    "\n",
    "# save output\n",
    "f = open('text_gen_output/RNN_large_textdata_output.txt', 'w')  # create an output file to write too\n",
    "\n",
    "# load weights\n",
    "model.load_weights('model_weights/best_RNN_large_textdata_weights.hdf5')\n",
    "for s in start_inds:\n",
    "    start_index = s\n",
    "    input_chars = text[start_index: start_index + window_size]\n",
    "\n",
    "    # use the prediction function\n",
    "    predict_input = predict_next_chars(model,input_chars,num_to_predict = 100)\n",
    "\n",
    "    # print out input characters\n",
    "    line = '-------------------' + '\\n'\n",
    "    print(line)\n",
    "    f.write(line)\n",
    "\n",
    "    input_line = 'input chars = ' + '\\n' +  input_chars + '\"' + '\\n'\n",
    "    print(input_line)\n",
    "    f.write(input_line)\n",
    "\n",
    "    # print out predicted characters\n",
    "    predict_line = 'predicted chars = ' + '\\n' +  predict_input + '\"' + '\\n'\n",
    "    print(predict_line)\n",
    "    f.write(predict_line)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
